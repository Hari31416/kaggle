{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport tqdm\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom sklearn.linear_model import LinearRegression, ElasticNet\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom xgboost import XGBRegressor\n\nfrom sklearn.metrics import (\n    mean_squared_error,\n    r2_score,\n    mean_absolute_error,\n    mean_squared_log_error,\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:16:08.331197Z","iopub.execute_input":"2022-06-26T10:16:08.331808Z","iopub.status.idle":"2022-06-26T10:16:09.680025Z","shell.execute_reply.started":"2022-06-26T10:16:08.331721Z","shell.execute_reply":"2022-06-26T10:16:09.678898Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Downloading Files","metadata":{}},{"cell_type":"markdown","source":"## The *small* datasets","metadata":{}},{"cell_type":"code","source":"!wget https://h31416-ml-datasets.s3.ap-south-1.amazonaws.com/store_sales/store_sales_small.zip","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:16:55.037282Z","iopub.execute_input":"2022-06-26T10:16:55.037718Z","iopub.status.idle":"2022-06-26T10:17:13.862831Z","shell.execute_reply.started":"2022-06-26T10:16:55.037662Z","shell.execute_reply":"2022-06-26T10:17:13.861489Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"--2022-06-26 10:16:55--  https://h31416-ml-datasets.s3.ap-south-1.amazonaws.com/store_sales/store_sales_small.zip\nResolving h31416-ml-datasets.s3.ap-south-1.amazonaws.com (h31416-ml-datasets.s3.ap-south-1.amazonaws.com)... 52.219.160.50\nConnecting to h31416-ml-datasets.s3.ap-south-1.amazonaws.com (h31416-ml-datasets.s3.ap-south-1.amazonaws.com)|52.219.160.50|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 197658254 (189M) [application/zip]\nSaving to: ‘store_sales_small.zip’\n\nstore_sales_small.z 100%[===================>] 188.50M  12.3MB/s    in 17s     \n\n2022-06-26 10:17:13 (11.1 MB/s) - ‘store_sales_small.zip’ saved [197658254/197658254]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!unzip store_sales_small.zip","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:17:13.864851Z","iopub.execute_input":"2022-06-26T10:17:13.865217Z","iopub.status.idle":"2022-06-26T10:17:16.007840Z","shell.execute_reply.started":"2022-06-26T10:17:13.865183Z","shell.execute_reply":"2022-06-26T10:17:16.006564Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Archive:  store_sales_small.zip\n extracting: data/small/test/A_BEVERAGE.csv  \n extracting: data/small/test/A_ELECTRONICS.csv  \n extracting: data/small/test/A_FOOD.csv  \n extracting: data/small/test/A_GROCERY.csv  \n extracting: data/small/test/A_HOUSEHOLD.csv  \n extracting: data/small/test/A_LADIES.csv  \n extracting: data/small/test/A_MISC.csv  \n extracting: data/small/test/A_STATIONARY.csv  \n extracting: data/small/test/B_BEVERAGE.csv  \n extracting: data/small/test/B_ELECTRONICS.csv  \n extracting: data/small/test/B_FOOD.csv  \n extracting: data/small/test/B_GROCERY.csv  \n extracting: data/small/test/B_HOUSEHOLD.csv  \n extracting: data/small/test/B_LADIES.csv  \n extracting: data/small/test/B_MISC.csv  \n extracting: data/small/test/B_STATIONARY.csv  \n extracting: data/small/test/C_BEVERAGE.csv  \n extracting: data/small/test/C_ELECTRONICS.csv  \n extracting: data/small/test/C_FOOD.csv  \n extracting: data/small/test/C_GROCERY.csv  \n extracting: data/small/test/C_HOUSEHOLD.csv  \n extracting: data/small/test/C_LADIES.csv  \n extracting: data/small/test/C_MISC.csv  \n extracting: data/small/test/C_STATIONARY.csv  \n extracting: data/small/test/D_BEVERAGE.csv  \n extracting: data/small/test/D_ELECTRONICS.csv  \n extracting: data/small/test/D_FOOD.csv  \n extracting: data/small/test/D_GROCERY.csv  \n extracting: data/small/test/D_HOUSEHOLD.csv  \n extracting: data/small/test/D_LADIES.csv  \n extracting: data/small/test/D_MISC.csv  \n extracting: data/small/test/D_STATIONARY.csv  \n extracting: data/small/test/E_BEVERAGE.csv  \n extracting: data/small/test/E_ELECTRONICS.csv  \n extracting: data/small/test/E_FOOD.csv  \n extracting: data/small/test/E_GROCERY.csv  \n extracting: data/small/test/E_HOUSEHOLD.csv  \n extracting: data/small/test/E_LADIES.csv  \n extracting: data/small/test/E_MISC.csv  \n extracting: data/small/test/E_STATIONARY.csv  \n extracting: data/small/test/F_BEVERAGE.csv  \n extracting: data/small/test/F_ELECTRONICS.csv  \n extracting: data/small/test/F_FOOD.csv  \n extracting: data/small/test/F_GROCERY.csv  \n extracting: data/small/test/F_HOUSEHOLD.csv  \n extracting: data/small/test/F_LADIES.csv  \n extracting: data/small/test/F_MISC.csv  \n extracting: data/small/test/F_STATIONARY.csv  \n extracting: data/small/test/G_BEVERAGE.csv  \n extracting: data/small/test/G_ELECTRONICS.csv  \n extracting: data/small/test/G_FOOD.csv  \n extracting: data/small/test/G_GROCERY.csv  \n extracting: data/small/test/G_HOUSEHOLD.csv  \n extracting: data/small/test/G_LADIES.csv  \n extracting: data/small/test/G_MISC.csv  \n extracting: data/small/test/G_STATIONARY.csv  \n extracting: data/small/test/H_BEVERAGE.csv  \n extracting: data/small/test/H_ELECTRONICS.csv  \n extracting: data/small/test/H_FOOD.csv  \n extracting: data/small/test/H_GROCERY.csv  \n extracting: data/small/test/H_HOUSEHOLD.csv  \n extracting: data/small/test/H_LADIES.csv  \n extracting: data/small/test/H_MISC.csv  \n extracting: data/small/test/H_STATIONARY.csv  \n extracting: data/small/test/I_BEVERAGE.csv  \n extracting: data/small/test/I_ELECTRONICS.csv  \n extracting: data/small/test/I_FOOD.csv  \n extracting: data/small/test/I_GROCERY.csv  \n extracting: data/small/test/I_HOUSEHOLD.csv  \n extracting: data/small/test/I_LADIES.csv  \n extracting: data/small/test/I_MISC.csv  \n extracting: data/small/test/I_STATIONARY.csv  \n extracting: data/small/test/J_BEVERAGE.csv  \n extracting: data/small/test/J_ELECTRONICS.csv  \n extracting: data/small/test/J_FOOD.csv  \n extracting: data/small/test/J_GROCERY.csv  \n extracting: data/small/test/J_HOUSEHOLD.csv  \n extracting: data/small/test/J_LADIES.csv  \n extracting: data/small/test/J_MISC.csv  \n extracting: data/small/test/J_STATIONARY.csv  \n extracting: data/small/test/Z_BEVERAGE.csv  \n extracting: data/small/test/Z_ELECTRONICS.csv  \n extracting: data/small/test/Z_FOOD.csv  \n extracting: data/small/test/Z_GROCERY.csv  \n extracting: data/small/test/Z_HOUSEHOLD.csv  \n extracting: data/small/test/Z_LADIES.csv  \n extracting: data/small/test/Z_MISC.csv  \n extracting: data/small/test/Z_STATIONARY.csv  \n extracting: data/small/train/A_BEVERAGE.csv  \n extracting: data/small/train/A_ELECTRONICS.csv  \n extracting: data/small/train/A_FOOD.csv  \n extracting: data/small/train/A_GROCERY.csv  \n extracting: data/small/train/A_HOUSEHOLD.csv  \n extracting: data/small/train/A_LADIES.csv  \n extracting: data/small/train/A_MISC.csv  \n extracting: data/small/train/A_STATIONARY.csv  \n extracting: data/small/train/B_BEVERAGE.csv  \n extracting: data/small/train/B_ELECTRONICS.csv  \n extracting: data/small/train/B_FOOD.csv  \n extracting: data/small/train/B_GROCERY.csv  \n extracting: data/small/train/B_HOUSEHOLD.csv  \n extracting: data/small/train/B_LADIES.csv  \n extracting: data/small/train/B_MISC.csv  \n extracting: data/small/train/B_STATIONARY.csv  \n extracting: data/small/train/C_BEVERAGE.csv  \n extracting: data/small/train/C_ELECTRONICS.csv  \n extracting: data/small/train/C_FOOD.csv  \n extracting: data/small/train/C_GROCERY.csv  \n extracting: data/small/train/C_HOUSEHOLD.csv  \n extracting: data/small/train/C_LADIES.csv  \n extracting: data/small/train/C_MISC.csv  \n extracting: data/small/train/C_STATIONARY.csv  \n extracting: data/small/train/D_BEVERAGE.csv  \n extracting: data/small/train/D_ELECTRONICS.csv  \n extracting: data/small/train/D_FOOD.csv  \n extracting: data/small/train/D_GROCERY.csv  \n extracting: data/small/train/D_HOUSEHOLD.csv  \n extracting: data/small/train/D_LADIES.csv  \n extracting: data/small/train/D_MISC.csv  \n extracting: data/small/train/D_STATIONARY.csv  \n extracting: data/small/train/E_BEVERAGE.csv  \n extracting: data/small/train/E_ELECTRONICS.csv  \n extracting: data/small/train/E_FOOD.csv  \n extracting: data/small/train/E_GROCERY.csv  \n extracting: data/small/train/E_HOUSEHOLD.csv  \n extracting: data/small/train/E_LADIES.csv  \n extracting: data/small/train/E_MISC.csv  \n extracting: data/small/train/E_STATIONARY.csv  \n extracting: data/small/train/F_BEVERAGE.csv  \n extracting: data/small/train/F_ELECTRONICS.csv  \n extracting: data/small/train/F_FOOD.csv  \n extracting: data/small/train/F_GROCERY.csv  \n extracting: data/small/train/F_HOUSEHOLD.csv  \n extracting: data/small/train/F_LADIES.csv  \n extracting: data/small/train/F_MISC.csv  \n extracting: data/small/train/F_STATIONARY.csv  \n extracting: data/small/train/G_BEVERAGE.csv  \n extracting: data/small/train/G_ELECTRONICS.csv  \n extracting: data/small/train/G_FOOD.csv  \n extracting: data/small/train/G_GROCERY.csv  \n extracting: data/small/train/G_HOUSEHOLD.csv  \n extracting: data/small/train/G_LADIES.csv  \n extracting: data/small/train/G_MISC.csv  \n extracting: data/small/train/G_STATIONARY.csv  \n extracting: data/small/train/H_BEVERAGE.csv  \n extracting: data/small/train/H_ELECTRONICS.csv  \n extracting: data/small/train/H_FOOD.csv  \n extracting: data/small/train/H_GROCERY.csv  \n extracting: data/small/train/H_HOUSEHOLD.csv  \n extracting: data/small/train/H_LADIES.csv  \n extracting: data/small/train/H_MISC.csv  \n extracting: data/small/train/H_STATIONARY.csv  \n extracting: data/small/train/I_BEVERAGE.csv  \n extracting: data/small/train/I_ELECTRONICS.csv  \n extracting: data/small/train/I_FOOD.csv  \n extracting: data/small/train/I_GROCERY.csv  \n extracting: data/small/train/I_HOUSEHOLD.csv  \n extracting: data/small/train/I_LADIES.csv  \n extracting: data/small/train/I_MISC.csv  \n extracting: data/small/train/I_STATIONARY.csv  \n extracting: data/small/train/J_BEVERAGE.csv  \n extracting: data/small/train/J_ELECTRONICS.csv  \n extracting: data/small/train/J_FOOD.csv  \n extracting: data/small/train/J_GROCERY.csv  \n extracting: data/small/train/J_HOUSEHOLD.csv  \n extracting: data/small/train/J_LADIES.csv  \n extracting: data/small/train/J_MISC.csv  \n extracting: data/small/train/J_STATIONARY.csv  \n extracting: data/small/train/Z_BEVERAGE.csv  \n extracting: data/small/train/Z_ELECTRONICS.csv  \n extracting: data/small/train/Z_FOOD.csv  \n extracting: data/small/train/Z_GROCERY.csv  \n extracting: data/small/train/Z_HOUSEHOLD.csv  \n extracting: data/small/train/Z_LADIES.csv  \n extracting: data/small/train/Z_MISC.csv  \n extracting: data/small/train/Z_STATIONARY.csv  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## The *large* Datasets","metadata":{}},{"cell_type":"code","source":"!wget https://h31416-ml-datasets.s3.ap-south-1.amazonaws.com/store_sales/store_sales_large.zip","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:18:08.907321Z","iopub.execute_input":"2022-06-26T10:18:08.907814Z","iopub.status.idle":"2022-06-26T10:18:26.895208Z","shell.execute_reply.started":"2022-06-26T10:18:08.907774Z","shell.execute_reply":"2022-06-26T10:18:26.894081Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"--2022-06-26 10:18:09--  https://h31416-ml-datasets.s3.ap-south-1.amazonaws.com/store_sales/store_sales_large.zip\nResolving h31416-ml-datasets.s3.ap-south-1.amazonaws.com (h31416-ml-datasets.s3.ap-south-1.amazonaws.com)... 52.219.156.158\nConnecting to h31416-ml-datasets.s3.ap-south-1.amazonaws.com (h31416-ml-datasets.s3.ap-south-1.amazonaws.com)|52.219.156.158|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 188496690 (180M) [application/zip]\nSaving to: ‘store_sales_large.zip’\n\nstore_sales_large.z 100%[===================>] 179.76M  12.4MB/s    in 16s     \n\n2022-06-26 10:18:26 (11.1 MB/s) - ‘store_sales_large.zip’ saved [188496690/188496690]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!unzip store_sales_large.zip","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:18:26.897181Z","iopub.execute_input":"2022-06-26T10:18:26.897535Z","iopub.status.idle":"2022-06-26T10:18:29.044581Z","shell.execute_reply.started":"2022-06-26T10:18:26.897502Z","shell.execute_reply":"2022-06-26T10:18:29.043049Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Archive:  store_sales_large.zip\n extracting: data/large/test_large/A_AUTOMOTIVE.csv  \n extracting: data/large/test_large/A_BABY CARE.csv  \n extracting: data/large/test_large/A_BEAUTY.csv  \n extracting: data/large/test_large/A_BEVERAGES.csv  \n extracting: data/large/test_large/A_BOOKS.csv  \n extracting: data/large/test_large/A_BREAD_BAKERY.csv  \n extracting: data/large/test_large/A_CELEBRATION.csv  \n extracting: data/large/test_large/A_CLEANING.csv  \n extracting: data/large/test_large/A_DAIRY.csv  \n extracting: data/large/test_large/A_DELI.csv  \n extracting: data/large/test_large/A_EGGS.csv  \n extracting: data/large/test_large/A_FROZEN FOODS.csv  \n extracting: data/large/test_large/A_GROCERY I.csv  \n extracting: data/large/test_large/A_GROCERY II.csv  \n extracting: data/large/test_large/A_HARDWARE.csv  \n extracting: data/large/test_large/A_HOME AND KITCHEN I.csv  \n extracting: data/large/test_large/A_HOME AND KITCHEN II.csv  \n extracting: data/large/test_large/A_HOME APPLIANCES.csv  \n extracting: data/large/test_large/A_HOME CARE.csv  \n extracting: data/large/test_large/A_LADIESWEAR.csv  \n extracting: data/large/test_large/A_LAWN AND GARDEN.csv  \n extracting: data/large/test_large/A_LINGERIE.csv  \n extracting: data/large/test_large/A_LIQUOR,WINE,BEER.csv  \n extracting: data/large/test_large/A_MAGAZINES.csv  \n extracting: data/large/test_large/A_MEATS.csv  \n extracting: data/large/test_large/A_PERSONAL CARE.csv  \n extracting: data/large/test_large/A_PET SUPPLIES.csv  \n extracting: data/large/test_large/A_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/test_large/A_POULTRY.csv  \n extracting: data/large/test_large/A_PREPARED FOODS.csv  \n extracting: data/large/test_large/A_PRODUCE.csv  \n extracting: data/large/test_large/A_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/test_large/A_SEAFOOD.csv  \n extracting: data/large/test_large/B_AUTOMOTIVE.csv  \n extracting: data/large/test_large/B_BABY CARE.csv  \n extracting: data/large/test_large/B_BEAUTY.csv  \n extracting: data/large/test_large/B_BEVERAGES.csv  \n extracting: data/large/test_large/B_BOOKS.csv  \n extracting: data/large/test_large/B_BREAD_BAKERY.csv  \n extracting: data/large/test_large/B_CELEBRATION.csv  \n extracting: data/large/test_large/B_CLEANING.csv  \n extracting: data/large/test_large/B_DAIRY.csv  \n extracting: data/large/test_large/B_DELI.csv  \n extracting: data/large/test_large/B_EGGS.csv  \n extracting: data/large/test_large/B_FROZEN FOODS.csv  \n extracting: data/large/test_large/B_GROCERY I.csv  \n extracting: data/large/test_large/B_GROCERY II.csv  \n extracting: data/large/test_large/B_HARDWARE.csv  \n extracting: data/large/test_large/B_HOME AND KITCHEN I.csv  \n extracting: data/large/test_large/B_HOME AND KITCHEN II.csv  \n extracting: data/large/test_large/B_HOME APPLIANCES.csv  \n extracting: data/large/test_large/B_HOME CARE.csv  \n extracting: data/large/test_large/B_LADIESWEAR.csv  \n extracting: data/large/test_large/B_LAWN AND GARDEN.csv  \n extracting: data/large/test_large/B_LINGERIE.csv  \n extracting: data/large/test_large/B_LIQUOR,WINE,BEER.csv  \n extracting: data/large/test_large/B_MAGAZINES.csv  \n extracting: data/large/test_large/B_MEATS.csv  \n extracting: data/large/test_large/B_PERSONAL CARE.csv  \n extracting: data/large/test_large/B_PET SUPPLIES.csv  \n extracting: data/large/test_large/B_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/test_large/B_POULTRY.csv  \n extracting: data/large/test_large/B_PREPARED FOODS.csv  \n extracting: data/large/test_large/B_PRODUCE.csv  \n extracting: data/large/test_large/B_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/test_large/B_SEAFOOD.csv  \n extracting: data/large/test_large/C_AUTOMOTIVE.csv  \n extracting: data/large/test_large/C_BABY CARE.csv  \n extracting: data/large/test_large/C_BEAUTY.csv  \n extracting: data/large/test_large/C_BEVERAGES.csv  \n extracting: data/large/test_large/C_BOOKS.csv  \n extracting: data/large/test_large/C_BREAD_BAKERY.csv  \n extracting: data/large/test_large/C_CELEBRATION.csv  \n extracting: data/large/test_large/C_CLEANING.csv  \n extracting: data/large/test_large/C_DAIRY.csv  \n extracting: data/large/test_large/C_DELI.csv  \n extracting: data/large/test_large/C_EGGS.csv  \n extracting: data/large/test_large/C_FROZEN FOODS.csv  \n extracting: data/large/test_large/C_GROCERY I.csv  \n extracting: data/large/test_large/C_GROCERY II.csv  \n extracting: data/large/test_large/C_HARDWARE.csv  \n extracting: data/large/test_large/C_HOME AND KITCHEN I.csv  \n extracting: data/large/test_large/C_HOME AND KITCHEN II.csv  \n extracting: data/large/test_large/C_HOME APPLIANCES.csv  \n extracting: data/large/test_large/C_HOME CARE.csv  \n extracting: data/large/test_large/C_LADIESWEAR.csv  \n extracting: data/large/test_large/C_LAWN AND GARDEN.csv  \n extracting: data/large/test_large/C_LINGERIE.csv  \n extracting: data/large/test_large/C_LIQUOR,WINE,BEER.csv  \n extracting: data/large/test_large/C_MAGAZINES.csv  \n extracting: data/large/test_large/C_MEATS.csv  \n extracting: data/large/test_large/C_PERSONAL CARE.csv  \n extracting: data/large/test_large/C_PET SUPPLIES.csv  \n extracting: data/large/test_large/C_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/test_large/C_POULTRY.csv  \n extracting: data/large/test_large/C_PREPARED FOODS.csv  \n extracting: data/large/test_large/C_PRODUCE.csv  \n extracting: data/large/test_large/C_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/test_large/C_SEAFOOD.csv  \n extracting: data/large/test_large/D_AUTOMOTIVE.csv  \n extracting: data/large/test_large/D_BABY CARE.csv  \n extracting: data/large/test_large/D_BEAUTY.csv  \n extracting: data/large/test_large/D_BEVERAGES.csv  \n extracting: data/large/test_large/D_BOOKS.csv  \n extracting: data/large/test_large/D_BREAD_BAKERY.csv  \n extracting: data/large/test_large/D_CELEBRATION.csv  \n extracting: data/large/test_large/D_CLEANING.csv  \n extracting: data/large/test_large/D_DAIRY.csv  \n extracting: data/large/test_large/D_DELI.csv  \n extracting: data/large/test_large/D_EGGS.csv  \n extracting: data/large/test_large/D_FROZEN FOODS.csv  \n extracting: data/large/test_large/D_GROCERY I.csv  \n extracting: data/large/test_large/D_GROCERY II.csv  \n extracting: data/large/test_large/D_HARDWARE.csv  \n extracting: data/large/test_large/D_HOME AND KITCHEN I.csv  \n extracting: data/large/test_large/D_HOME AND KITCHEN II.csv  \n extracting: data/large/test_large/D_HOME APPLIANCES.csv  \n extracting: data/large/test_large/D_HOME CARE.csv  \n extracting: data/large/test_large/D_LADIESWEAR.csv  \n extracting: data/large/test_large/D_LAWN AND GARDEN.csv  \n extracting: data/large/test_large/D_LINGERIE.csv  \n extracting: data/large/test_large/D_LIQUOR,WINE,BEER.csv  \n extracting: data/large/test_large/D_MAGAZINES.csv  \n extracting: data/large/test_large/D_MEATS.csv  \n extracting: data/large/test_large/D_PERSONAL CARE.csv  \n extracting: data/large/test_large/D_PET SUPPLIES.csv  \n extracting: data/large/test_large/D_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/test_large/D_POULTRY.csv  \n extracting: data/large/test_large/D_PREPARED FOODS.csv  \n extracting: data/large/test_large/D_PRODUCE.csv  \n extracting: data/large/test_large/D_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/test_large/D_SEAFOOD.csv  \n extracting: data/large/test_large/E_AUTOMOTIVE.csv  \n extracting: data/large/test_large/E_BABY CARE.csv  \n extracting: data/large/test_large/E_BEAUTY.csv  \n extracting: data/large/test_large/E_BEVERAGES.csv  \n extracting: data/large/test_large/E_BOOKS.csv  \n extracting: data/large/test_large/E_BREAD_BAKERY.csv  \n extracting: data/large/test_large/E_CELEBRATION.csv  \n extracting: data/large/test_large/E_CLEANING.csv  \n extracting: data/large/test_large/E_DAIRY.csv  \n extracting: data/large/test_large/E_DELI.csv  \n extracting: data/large/test_large/E_EGGS.csv  \n extracting: data/large/test_large/E_FROZEN FOODS.csv  \n extracting: data/large/test_large/E_GROCERY I.csv  \n extracting: data/large/test_large/E_GROCERY II.csv  \n extracting: data/large/test_large/E_HARDWARE.csv  \n extracting: data/large/test_large/E_HOME AND KITCHEN I.csv  \n extracting: data/large/test_large/E_HOME AND KITCHEN II.csv  \n extracting: data/large/test_large/E_HOME APPLIANCES.csv  \n extracting: data/large/test_large/E_HOME CARE.csv  \n extracting: data/large/test_large/E_LADIESWEAR.csv  \n extracting: data/large/test_large/E_LAWN AND GARDEN.csv  \n extracting: data/large/test_large/E_LINGERIE.csv  \n extracting: data/large/test_large/E_LIQUOR,WINE,BEER.csv  \n extracting: data/large/test_large/E_MAGAZINES.csv  \n extracting: data/large/test_large/E_MEATS.csv  \n extracting: data/large/test_large/E_PERSONAL CARE.csv  \n extracting: data/large/test_large/E_PET SUPPLIES.csv  \n extracting: data/large/test_large/E_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/test_large/E_POULTRY.csv  \n extracting: data/large/test_large/E_PREPARED FOODS.csv  \n extracting: data/large/test_large/E_PRODUCE.csv  \n extracting: data/large/test_large/E_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/test_large/E_SEAFOOD.csv  \n extracting: data/large/test_large/F_AUTOMOTIVE.csv  \n extracting: data/large/test_large/F_BABY CARE.csv  \n extracting: data/large/test_large/F_BEAUTY.csv  \n extracting: data/large/test_large/F_BEVERAGES.csv  \n extracting: data/large/test_large/F_BOOKS.csv  \n extracting: data/large/test_large/F_BREAD_BAKERY.csv  \n extracting: data/large/test_large/F_CELEBRATION.csv  \n extracting: data/large/test_large/F_CLEANING.csv  \n extracting: data/large/test_large/F_DAIRY.csv  \n extracting: data/large/test_large/F_DELI.csv  \n extracting: data/large/test_large/F_EGGS.csv  \n extracting: data/large/test_large/F_FROZEN FOODS.csv  \n extracting: data/large/test_large/F_GROCERY I.csv  \n extracting: data/large/test_large/F_GROCERY II.csv  \n extracting: data/large/test_large/F_HARDWARE.csv  \n extracting: data/large/test_large/F_HOME AND KITCHEN I.csv  \n extracting: data/large/test_large/F_HOME AND KITCHEN II.csv  \n extracting: data/large/test_large/F_HOME APPLIANCES.csv  \n extracting: data/large/test_large/F_HOME CARE.csv  \n extracting: data/large/test_large/F_LADIESWEAR.csv  \n extracting: data/large/test_large/F_LAWN AND GARDEN.csv  \n extracting: data/large/test_large/F_LINGERIE.csv  \n extracting: data/large/test_large/F_LIQUOR,WINE,BEER.csv  \n extracting: data/large/test_large/F_MAGAZINES.csv  \n extracting: data/large/test_large/F_MEATS.csv  \n extracting: data/large/test_large/F_PERSONAL CARE.csv  \n extracting: data/large/test_large/F_PET SUPPLIES.csv  \n extracting: data/large/test_large/F_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/test_large/F_POULTRY.csv  \n extracting: data/large/test_large/F_PREPARED FOODS.csv  \n extracting: data/large/test_large/F_PRODUCE.csv  \n extracting: data/large/test_large/F_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/test_large/F_SEAFOOD.csv  \n extracting: data/large/test_large/G_AUTOMOTIVE.csv  \n extracting: data/large/test_large/G_BABY CARE.csv  \n extracting: data/large/test_large/G_BEAUTY.csv  \n extracting: data/large/test_large/G_BEVERAGES.csv  \n extracting: data/large/test_large/G_BOOKS.csv  \n extracting: data/large/test_large/G_BREAD_BAKERY.csv  \n extracting: data/large/test_large/G_CELEBRATION.csv  \n extracting: data/large/test_large/G_CLEANING.csv  \n extracting: data/large/test_large/G_DAIRY.csv  \n extracting: data/large/test_large/G_DELI.csv  \n extracting: data/large/test_large/G_EGGS.csv  \n extracting: data/large/test_large/G_FROZEN FOODS.csv  \n extracting: data/large/test_large/G_GROCERY I.csv  \n extracting: data/large/test_large/G_GROCERY II.csv  \n extracting: data/large/test_large/G_HARDWARE.csv  \n extracting: data/large/test_large/G_HOME AND KITCHEN I.csv  \n extracting: data/large/test_large/G_HOME AND KITCHEN II.csv  \n extracting: data/large/test_large/G_HOME APPLIANCES.csv  \n extracting: data/large/test_large/G_HOME CARE.csv  \n extracting: data/large/test_large/G_LADIESWEAR.csv  \n extracting: data/large/test_large/G_LAWN AND GARDEN.csv  \n extracting: data/large/test_large/G_LINGERIE.csv  \n extracting: data/large/test_large/G_LIQUOR,WINE,BEER.csv  \n extracting: data/large/test_large/G_MAGAZINES.csv  \n extracting: data/large/test_large/G_MEATS.csv  \n extracting: data/large/test_large/G_PERSONAL CARE.csv  \n extracting: data/large/test_large/G_PET SUPPLIES.csv  \n extracting: data/large/test_large/G_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/test_large/G_POULTRY.csv  \n extracting: data/large/test_large/G_PREPARED FOODS.csv  \n extracting: data/large/test_large/G_PRODUCE.csv  \n extracting: data/large/test_large/G_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/test_large/G_SEAFOOD.csv  \n extracting: data/large/test_large/H_AUTOMOTIVE.csv  \n extracting: data/large/test_large/H_BABY CARE.csv  \n extracting: data/large/test_large/H_BEAUTY.csv  \n extracting: data/large/test_large/H_BEVERAGES.csv  \n extracting: data/large/test_large/H_BOOKS.csv  \n extracting: data/large/test_large/H_BREAD_BAKERY.csv  \n extracting: data/large/test_large/H_CELEBRATION.csv  \n extracting: data/large/test_large/H_CLEANING.csv  \n extracting: data/large/test_large/H_DAIRY.csv  \n extracting: data/large/test_large/H_DELI.csv  \n extracting: data/large/test_large/H_EGGS.csv  \n extracting: data/large/test_large/H_FROZEN FOODS.csv  \n extracting: data/large/test_large/H_GROCERY I.csv  \n extracting: data/large/test_large/H_GROCERY II.csv  \n extracting: data/large/test_large/H_HARDWARE.csv  \n extracting: data/large/test_large/H_HOME AND KITCHEN I.csv  \n extracting: data/large/test_large/H_HOME AND KITCHEN II.csv  \n extracting: data/large/test_large/H_HOME APPLIANCES.csv  \n extracting: data/large/test_large/H_HOME CARE.csv  \n extracting: data/large/test_large/H_LADIESWEAR.csv  \n extracting: data/large/test_large/H_LAWN AND GARDEN.csv  \n extracting: data/large/test_large/H_LINGERIE.csv  \n extracting: data/large/test_large/H_LIQUOR,WINE,BEER.csv  \n extracting: data/large/test_large/H_MAGAZINES.csv  \n extracting: data/large/test_large/H_MEATS.csv  \n extracting: data/large/test_large/H_PERSONAL CARE.csv  \n extracting: data/large/test_large/H_PET SUPPLIES.csv  \n extracting: data/large/test_large/H_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/test_large/H_POULTRY.csv  \n extracting: data/large/test_large/H_PREPARED FOODS.csv  \n extracting: data/large/test_large/H_PRODUCE.csv  \n extracting: data/large/test_large/H_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/test_large/H_SEAFOOD.csv  \n extracting: data/large/test_large/I_AUTOMOTIVE.csv  \n extracting: data/large/test_large/I_BABY CARE.csv  \n extracting: data/large/test_large/I_BEAUTY.csv  \n extracting: data/large/test_large/I_BEVERAGES.csv  \n extracting: data/large/test_large/I_BOOKS.csv  \n extracting: data/large/test_large/I_BREAD_BAKERY.csv  \n extracting: data/large/test_large/I_CELEBRATION.csv  \n extracting: data/large/test_large/I_CLEANING.csv  \n extracting: data/large/test_large/I_DAIRY.csv  \n extracting: data/large/test_large/I_DELI.csv  \n extracting: data/large/test_large/I_EGGS.csv  \n extracting: data/large/test_large/I_FROZEN FOODS.csv  \n extracting: data/large/test_large/I_GROCERY I.csv  \n extracting: data/large/test_large/I_GROCERY II.csv  \n extracting: data/large/test_large/I_HARDWARE.csv  \n extracting: data/large/test_large/I_HOME AND KITCHEN I.csv  \n extracting: data/large/test_large/I_HOME AND KITCHEN II.csv  \n extracting: data/large/test_large/I_HOME APPLIANCES.csv  \n extracting: data/large/test_large/I_HOME CARE.csv  \n extracting: data/large/test_large/I_LADIESWEAR.csv  \n extracting: data/large/test_large/I_LAWN AND GARDEN.csv  \n extracting: data/large/test_large/I_LINGERIE.csv  \n extracting: data/large/test_large/I_LIQUOR,WINE,BEER.csv  \n extracting: data/large/test_large/I_MAGAZINES.csv  \n extracting: data/large/test_large/I_MEATS.csv  \n extracting: data/large/test_large/I_PERSONAL CARE.csv  \n extracting: data/large/test_large/I_PET SUPPLIES.csv  \n extracting: data/large/test_large/I_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/test_large/I_POULTRY.csv  \n extracting: data/large/test_large/I_PREPARED FOODS.csv  \n extracting: data/large/test_large/I_PRODUCE.csv  \n extracting: data/large/test_large/I_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/test_large/I_SEAFOOD.csv  \n extracting: data/large/test_large/J_AUTOMOTIVE.csv  \n extracting: data/large/test_large/J_BABY CARE.csv  \n extracting: data/large/test_large/J_BEAUTY.csv  \n extracting: data/large/test_large/J_BEVERAGES.csv  \n extracting: data/large/test_large/J_BOOKS.csv  \n extracting: data/large/test_large/J_BREAD_BAKERY.csv  \n extracting: data/large/test_large/J_CELEBRATION.csv  \n extracting: data/large/test_large/J_CLEANING.csv  \n extracting: data/large/test_large/J_DAIRY.csv  \n extracting: data/large/test_large/J_DELI.csv  \n extracting: data/large/test_large/J_EGGS.csv  \n extracting: data/large/test_large/J_FROZEN FOODS.csv  \n extracting: data/large/test_large/J_GROCERY I.csv  \n extracting: data/large/test_large/J_GROCERY II.csv  \n extracting: data/large/test_large/J_HARDWARE.csv  \n extracting: data/large/test_large/J_HOME AND KITCHEN I.csv  \n extracting: data/large/test_large/J_HOME AND KITCHEN II.csv  \n extracting: data/large/test_large/J_HOME APPLIANCES.csv  \n extracting: data/large/test_large/J_HOME CARE.csv  \n extracting: data/large/test_large/J_LADIESWEAR.csv  \n extracting: data/large/test_large/J_LAWN AND GARDEN.csv  \n extracting: data/large/test_large/J_LINGERIE.csv  \n extracting: data/large/test_large/J_LIQUOR,WINE,BEER.csv  \n extracting: data/large/test_large/J_MAGAZINES.csv  \n extracting: data/large/test_large/J_MEATS.csv  \n extracting: data/large/test_large/J_PERSONAL CARE.csv  \n extracting: data/large/test_large/J_PET SUPPLIES.csv  \n extracting: data/large/test_large/J_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/test_large/J_POULTRY.csv  \n extracting: data/large/test_large/J_PREPARED FOODS.csv  \n extracting: data/large/test_large/J_PRODUCE.csv  \n extracting: data/large/test_large/J_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/test_large/J_SEAFOOD.csv  \n extracting: data/large/test_large/K_AUTOMOTIVE.csv  \n extracting: data/large/test_large/K_BABY CARE.csv  \n extracting: data/large/test_large/K_BEAUTY.csv  \n extracting: data/large/test_large/K_BEVERAGES.csv  \n extracting: data/large/test_large/K_BOOKS.csv  \n extracting: data/large/test_large/K_BREAD_BAKERY.csv  \n extracting: data/large/test_large/K_CELEBRATION.csv  \n extracting: data/large/test_large/K_CLEANING.csv  \n extracting: data/large/test_large/K_DAIRY.csv  \n extracting: data/large/test_large/K_DELI.csv  \n extracting: data/large/test_large/K_EGGS.csv  \n extracting: data/large/test_large/K_FROZEN FOODS.csv  \n extracting: data/large/test_large/K_GROCERY I.csv  \n extracting: data/large/test_large/K_GROCERY II.csv  \n extracting: data/large/test_large/K_HARDWARE.csv  \n extracting: data/large/test_large/K_HOME AND KITCHEN I.csv  \n extracting: data/large/test_large/K_HOME AND KITCHEN II.csv  \n extracting: data/large/test_large/K_HOME APPLIANCES.csv  \n extracting: data/large/test_large/K_HOME CARE.csv  \n extracting: data/large/test_large/K_LADIESWEAR.csv  \n extracting: data/large/test_large/K_LAWN AND GARDEN.csv  \n extracting: data/large/test_large/K_LINGERIE.csv  \n extracting: data/large/test_large/K_LIQUOR,WINE,BEER.csv  \n extracting: data/large/test_large/K_MAGAZINES.csv  \n extracting: data/large/test_large/K_MEATS.csv  \n extracting: data/large/test_large/K_PERSONAL CARE.csv  \n extracting: data/large/test_large/K_PET SUPPLIES.csv  \n extracting: data/large/test_large/K_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/test_large/K_POULTRY.csv  \n extracting: data/large/test_large/K_PREPARED FOODS.csv  \n extracting: data/large/test_large/K_PRODUCE.csv  \n extracting: data/large/test_large/K_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/test_large/K_SEAFOOD.csv  \n extracting: data/large/test_large/L_AUTOMOTIVE.csv  \n extracting: data/large/test_large/L_BABY CARE.csv  \n extracting: data/large/test_large/L_BEAUTY.csv  \n extracting: data/large/test_large/L_BEVERAGES.csv  \n extracting: data/large/test_large/L_BOOKS.csv  \n extracting: data/large/test_large/L_BREAD_BAKERY.csv  \n extracting: data/large/test_large/L_CELEBRATION.csv  \n extracting: data/large/test_large/L_CLEANING.csv  \n extracting: data/large/test_large/L_DAIRY.csv  \n extracting: data/large/test_large/L_DELI.csv  \n extracting: data/large/test_large/L_EGGS.csv  \n extracting: data/large/test_large/L_FROZEN FOODS.csv  \n extracting: data/large/test_large/L_GROCERY I.csv  \n extracting: data/large/test_large/L_GROCERY II.csv  \n extracting: data/large/test_large/L_HARDWARE.csv  \n extracting: data/large/test_large/L_HOME AND KITCHEN I.csv  \n extracting: data/large/test_large/L_HOME AND KITCHEN II.csv  \n extracting: data/large/test_large/L_HOME APPLIANCES.csv  \n extracting: data/large/test_large/L_HOME CARE.csv  \n extracting: data/large/test_large/L_LADIESWEAR.csv  \n extracting: data/large/test_large/L_LAWN AND GARDEN.csv  \n extracting: data/large/test_large/L_LINGERIE.csv  \n extracting: data/large/test_large/L_LIQUOR,WINE,BEER.csv  \n extracting: data/large/test_large/L_MAGAZINES.csv  \n extracting: data/large/test_large/L_MEATS.csv  \n extracting: data/large/test_large/L_PERSONAL CARE.csv  \n extracting: data/large/test_large/L_PET SUPPLIES.csv  \n extracting: data/large/test_large/L_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/test_large/L_POULTRY.csv  \n extracting: data/large/test_large/L_PREPARED FOODS.csv  \n extracting: data/large/test_large/L_PRODUCE.csv  \n extracting: data/large/test_large/L_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/test_large/L_SEAFOOD.csv  \n extracting: data/large/test_large/M_AUTOMOTIVE.csv  \n extracting: data/large/test_large/M_BABY CARE.csv  \n extracting: data/large/test_large/M_BEAUTY.csv  \n extracting: data/large/test_large/M_BEVERAGES.csv  \n extracting: data/large/test_large/M_BOOKS.csv  \n extracting: data/large/test_large/M_BREAD_BAKERY.csv  \n extracting: data/large/test_large/M_CELEBRATION.csv  \n extracting: data/large/test_large/M_CLEANING.csv  \n extracting: data/large/test_large/M_DAIRY.csv  \n extracting: data/large/test_large/M_DELI.csv  \n extracting: data/large/test_large/M_EGGS.csv  \n extracting: data/large/test_large/M_FROZEN FOODS.csv  \n extracting: data/large/test_large/M_GROCERY I.csv  \n extracting: data/large/test_large/M_GROCERY II.csv  \n extracting: data/large/test_large/M_HARDWARE.csv  \n extracting: data/large/test_large/M_HOME AND KITCHEN I.csv  \n extracting: data/large/test_large/M_HOME AND KITCHEN II.csv  \n extracting: data/large/test_large/M_HOME APPLIANCES.csv  \n extracting: data/large/test_large/M_HOME CARE.csv  \n extracting: data/large/test_large/M_LADIESWEAR.csv  \n extracting: data/large/test_large/M_LAWN AND GARDEN.csv  \n extracting: data/large/test_large/M_LINGERIE.csv  \n extracting: data/large/test_large/M_LIQUOR,WINE,BEER.csv  \n extracting: data/large/test_large/M_MAGAZINES.csv  \n extracting: data/large/test_large/M_MEATS.csv  \n extracting: data/large/test_large/M_PERSONAL CARE.csv  \n extracting: data/large/test_large/M_PET SUPPLIES.csv  \n extracting: data/large/test_large/M_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/test_large/M_POULTRY.csv  \n extracting: data/large/test_large/M_PREPARED FOODS.csv  \n extracting: data/large/test_large/M_PRODUCE.csv  \n extracting: data/large/test_large/M_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/test_large/M_SEAFOOD.csv  \n extracting: data/large/test_large/N_AUTOMOTIVE.csv  \n extracting: data/large/test_large/N_BABY CARE.csv  \n extracting: data/large/test_large/N_BEAUTY.csv  \n extracting: data/large/test_large/N_BEVERAGES.csv  \n extracting: data/large/test_large/N_BOOKS.csv  \n extracting: data/large/test_large/N_BREAD_BAKERY.csv  \n extracting: data/large/test_large/N_CELEBRATION.csv  \n extracting: data/large/test_large/N_CLEANING.csv  \n extracting: data/large/test_large/N_DAIRY.csv  \n extracting: data/large/test_large/N_DELI.csv  \n extracting: data/large/test_large/N_EGGS.csv  \n extracting: data/large/test_large/N_FROZEN FOODS.csv  \n extracting: data/large/test_large/N_GROCERY I.csv  \n extracting: data/large/test_large/N_GROCERY II.csv  \n extracting: data/large/test_large/N_HARDWARE.csv  \n extracting: data/large/test_large/N_HOME AND KITCHEN I.csv  \n extracting: data/large/test_large/N_HOME AND KITCHEN II.csv  \n extracting: data/large/test_large/N_HOME APPLIANCES.csv  \n extracting: data/large/test_large/N_HOME CARE.csv  \n extracting: data/large/test_large/N_LADIESWEAR.csv  \n extracting: data/large/test_large/N_LAWN AND GARDEN.csv  \n extracting: data/large/test_large/N_LINGERIE.csv  \n extracting: data/large/test_large/N_LIQUOR,WINE,BEER.csv  \n extracting: data/large/test_large/N_MAGAZINES.csv  \n extracting: data/large/test_large/N_MEATS.csv  \n extracting: data/large/test_large/N_PERSONAL CARE.csv  \n extracting: data/large/test_large/N_PET SUPPLIES.csv  \n extracting: data/large/test_large/N_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/test_large/N_POULTRY.csv  \n extracting: data/large/test_large/N_PREPARED FOODS.csv  \n extracting: data/large/test_large/N_PRODUCE.csv  \n extracting: data/large/test_large/N_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/test_large/N_SEAFOOD.csv  \n extracting: data/large/test_large/O_AUTOMOTIVE.csv  \n extracting: data/large/test_large/O_BABY CARE.csv  \n extracting: data/large/test_large/O_BEAUTY.csv  \n extracting: data/large/test_large/O_BEVERAGES.csv  \n extracting: data/large/test_large/O_BOOKS.csv  \n extracting: data/large/test_large/O_BREAD_BAKERY.csv  \n extracting: data/large/test_large/O_CELEBRATION.csv  \n extracting: data/large/test_large/O_CLEANING.csv  \n extracting: data/large/test_large/O_DAIRY.csv  \n extracting: data/large/test_large/O_DELI.csv  \n extracting: data/large/test_large/O_EGGS.csv  \n extracting: data/large/test_large/O_FROZEN FOODS.csv  \n extracting: data/large/test_large/O_GROCERY I.csv  \n extracting: data/large/test_large/O_GROCERY II.csv  \n extracting: data/large/test_large/O_HARDWARE.csv  \n extracting: data/large/test_large/O_HOME AND KITCHEN I.csv  \n extracting: data/large/test_large/O_HOME AND KITCHEN II.csv  \n extracting: data/large/test_large/O_HOME APPLIANCES.csv  \n extracting: data/large/test_large/O_HOME CARE.csv  \n extracting: data/large/test_large/O_LADIESWEAR.csv  \n extracting: data/large/test_large/O_LAWN AND GARDEN.csv  \n extracting: data/large/test_large/O_LINGERIE.csv  \n extracting: data/large/test_large/O_LIQUOR,WINE,BEER.csv  \n extracting: data/large/test_large/O_MAGAZINES.csv  \n extracting: data/large/test_large/O_MEATS.csv  \n extracting: data/large/test_large/O_PERSONAL CARE.csv  \n extracting: data/large/test_large/O_PET SUPPLIES.csv  \n extracting: data/large/test_large/O_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/test_large/O_POULTRY.csv  \n extracting: data/large/test_large/O_PREPARED FOODS.csv  \n extracting: data/large/test_large/O_PRODUCE.csv  \n extracting: data/large/test_large/O_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/test_large/O_SEAFOOD.csv  \n extracting: data/large/test_large/P_AUTOMOTIVE.csv  \n extracting: data/large/test_large/P_BABY CARE.csv  \n extracting: data/large/test_large/P_BEAUTY.csv  \n extracting: data/large/test_large/P_BEVERAGES.csv  \n extracting: data/large/test_large/P_BOOKS.csv  \n extracting: data/large/test_large/P_BREAD_BAKERY.csv  \n extracting: data/large/test_large/P_CELEBRATION.csv  \n extracting: data/large/test_large/P_CLEANING.csv  \n extracting: data/large/test_large/P_DAIRY.csv  \n extracting: data/large/test_large/P_DELI.csv  \n extracting: data/large/test_large/P_EGGS.csv  \n extracting: data/large/test_large/P_FROZEN FOODS.csv  \n extracting: data/large/test_large/P_GROCERY I.csv  \n extracting: data/large/test_large/P_GROCERY II.csv  \n extracting: data/large/test_large/P_HARDWARE.csv  \n extracting: data/large/test_large/P_HOME AND KITCHEN I.csv  \n extracting: data/large/test_large/P_HOME AND KITCHEN II.csv  \n extracting: data/large/test_large/P_HOME APPLIANCES.csv  \n extracting: data/large/test_large/P_HOME CARE.csv  \n extracting: data/large/test_large/P_LADIESWEAR.csv  \n extracting: data/large/test_large/P_LAWN AND GARDEN.csv  \n extracting: data/large/test_large/P_LINGERIE.csv  \n extracting: data/large/test_large/P_LIQUOR,WINE,BEER.csv  \n extracting: data/large/test_large/P_MAGAZINES.csv  \n extracting: data/large/test_large/P_MEATS.csv  \n extracting: data/large/test_large/P_PERSONAL CARE.csv  \n extracting: data/large/test_large/P_PET SUPPLIES.csv  \n extracting: data/large/test_large/P_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/test_large/P_POULTRY.csv  \n extracting: data/large/test_large/P_PREPARED FOODS.csv  \n extracting: data/large/test_large/P_PRODUCE.csv  \n extracting: data/large/test_large/P_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/test_large/P_SEAFOOD.csv  \n extracting: data/large/test_large/Q_AUTOMOTIVE.csv  \n extracting: data/large/test_large/Q_BABY CARE.csv  \n extracting: data/large/test_large/Q_BEAUTY.csv  \n extracting: data/large/test_large/Q_BEVERAGES.csv  \n extracting: data/large/test_large/Q_BOOKS.csv  \n extracting: data/large/test_large/Q_BREAD_BAKERY.csv  \n extracting: data/large/test_large/Q_CELEBRATION.csv  \n extracting: data/large/test_large/Q_CLEANING.csv  \n extracting: data/large/test_large/Q_DAIRY.csv  \n extracting: data/large/test_large/Q_DELI.csv  \n extracting: data/large/test_large/Q_EGGS.csv  \n extracting: data/large/test_large/Q_FROZEN FOODS.csv  \n extracting: data/large/test_large/Q_GROCERY I.csv  \n extracting: data/large/test_large/Q_GROCERY II.csv  \n extracting: data/large/test_large/Q_HARDWARE.csv  \n extracting: data/large/test_large/Q_HOME AND KITCHEN I.csv  \n extracting: data/large/test_large/Q_HOME AND KITCHEN II.csv  \n extracting: data/large/test_large/Q_HOME APPLIANCES.csv  \n extracting: data/large/test_large/Q_HOME CARE.csv  \n extracting: data/large/test_large/Q_LADIESWEAR.csv  \n extracting: data/large/test_large/Q_LAWN AND GARDEN.csv  \n extracting: data/large/test_large/Q_LINGERIE.csv  \n extracting: data/large/test_large/Q_LIQUOR,WINE,BEER.csv  \n extracting: data/large/test_large/Q_MAGAZINES.csv  \n extracting: data/large/test_large/Q_MEATS.csv  \n extracting: data/large/test_large/Q_PERSONAL CARE.csv  \n extracting: data/large/test_large/Q_PET SUPPLIES.csv  \n extracting: data/large/test_large/Q_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/test_large/Q_POULTRY.csv  \n extracting: data/large/test_large/Q_PREPARED FOODS.csv  \n extracting: data/large/test_large/Q_PRODUCE.csv  \n extracting: data/large/test_large/Q_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/test_large/Q_SEAFOOD.csv  \n extracting: data/large/train_large/A_AUTOMOTIVE.csv  \n extracting: data/large/train_large/A_BABY CARE.csv  \n extracting: data/large/train_large/A_BEAUTY.csv  \n extracting: data/large/train_large/A_BEVERAGES.csv  \n extracting: data/large/train_large/A_BOOKS.csv  \n extracting: data/large/train_large/A_BREAD_BAKERY.csv  \n extracting: data/large/train_large/A_CELEBRATION.csv  \n extracting: data/large/train_large/A_CLEANING.csv  \n extracting: data/large/train_large/A_DAIRY.csv  \n extracting: data/large/train_large/A_DELI.csv  \n extracting: data/large/train_large/A_EGGS.csv  \n extracting: data/large/train_large/A_FROZEN FOODS.csv  \n extracting: data/large/train_large/A_GROCERY I.csv  \n extracting: data/large/train_large/A_GROCERY II.csv  \n extracting: data/large/train_large/A_HARDWARE.csv  \n extracting: data/large/train_large/A_HOME AND KITCHEN I.csv  \n extracting: data/large/train_large/A_HOME AND KITCHEN II.csv  \n extracting: data/large/train_large/A_HOME APPLIANCES.csv  \n extracting: data/large/train_large/A_HOME CARE.csv  \n extracting: data/large/train_large/A_LADIESWEAR.csv  \n extracting: data/large/train_large/A_LAWN AND GARDEN.csv  \n extracting: data/large/train_large/A_LINGERIE.csv  \n extracting: data/large/train_large/A_LIQUOR,WINE,BEER.csv  \n extracting: data/large/train_large/A_MAGAZINES.csv  \n extracting: data/large/train_large/A_MEATS.csv  \n extracting: data/large/train_large/A_PERSONAL CARE.csv  \n extracting: data/large/train_large/A_PET SUPPLIES.csv  \n extracting: data/large/train_large/A_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/train_large/A_POULTRY.csv  \n extracting: data/large/train_large/A_PREPARED FOODS.csv  \n extracting: data/large/train_large/A_PRODUCE.csv  \n extracting: data/large/train_large/A_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/train_large/A_SEAFOOD.csv  \n extracting: data/large/train_large/B_AUTOMOTIVE.csv  \n extracting: data/large/train_large/B_BABY CARE.csv  \n extracting: data/large/train_large/B_BEAUTY.csv  \n extracting: data/large/train_large/B_BEVERAGES.csv  \n extracting: data/large/train_large/B_BOOKS.csv  \n extracting: data/large/train_large/B_BREAD_BAKERY.csv  \n extracting: data/large/train_large/B_CELEBRATION.csv  \n extracting: data/large/train_large/B_CLEANING.csv  \n extracting: data/large/train_large/B_DAIRY.csv  \n extracting: data/large/train_large/B_DELI.csv  \n extracting: data/large/train_large/B_EGGS.csv  \n extracting: data/large/train_large/B_FROZEN FOODS.csv  \n extracting: data/large/train_large/B_GROCERY I.csv  \n extracting: data/large/train_large/B_GROCERY II.csv  \n extracting: data/large/train_large/B_HARDWARE.csv  \n extracting: data/large/train_large/B_HOME AND KITCHEN I.csv  \n extracting: data/large/train_large/B_HOME AND KITCHEN II.csv  \n extracting: data/large/train_large/B_HOME APPLIANCES.csv  \n extracting: data/large/train_large/B_HOME CARE.csv  \n extracting: data/large/train_large/B_LADIESWEAR.csv  \n extracting: data/large/train_large/B_LAWN AND GARDEN.csv  \n extracting: data/large/train_large/B_LINGERIE.csv  \n extracting: data/large/train_large/B_LIQUOR,WINE,BEER.csv  \n extracting: data/large/train_large/B_MAGAZINES.csv  \n extracting: data/large/train_large/B_MEATS.csv  \n extracting: data/large/train_large/B_PERSONAL CARE.csv  \n extracting: data/large/train_large/B_PET SUPPLIES.csv  \n extracting: data/large/train_large/B_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/train_large/B_POULTRY.csv  \n extracting: data/large/train_large/B_PREPARED FOODS.csv  \n extracting: data/large/train_large/B_PRODUCE.csv  \n extracting: data/large/train_large/B_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/train_large/B_SEAFOOD.csv  \n extracting: data/large/train_large/C_AUTOMOTIVE.csv  \n extracting: data/large/train_large/C_BABY CARE.csv  \n extracting: data/large/train_large/C_BEAUTY.csv  \n extracting: data/large/train_large/C_BEVERAGES.csv  \n extracting: data/large/train_large/C_BOOKS.csv  \n extracting: data/large/train_large/C_BREAD_BAKERY.csv  \n extracting: data/large/train_large/C_CELEBRATION.csv  \n extracting: data/large/train_large/C_CLEANING.csv  \n extracting: data/large/train_large/C_DAIRY.csv  \n extracting: data/large/train_large/C_DELI.csv  \n extracting: data/large/train_large/C_EGGS.csv  \n extracting: data/large/train_large/C_FROZEN FOODS.csv  \n extracting: data/large/train_large/C_GROCERY I.csv  \n extracting: data/large/train_large/C_GROCERY II.csv  \n extracting: data/large/train_large/C_HARDWARE.csv  \n extracting: data/large/train_large/C_HOME AND KITCHEN I.csv  \n extracting: data/large/train_large/C_HOME AND KITCHEN II.csv  \n extracting: data/large/train_large/C_HOME APPLIANCES.csv  \n extracting: data/large/train_large/C_HOME CARE.csv  \n extracting: data/large/train_large/C_LADIESWEAR.csv  \n extracting: data/large/train_large/C_LAWN AND GARDEN.csv  \n extracting: data/large/train_large/C_LINGERIE.csv  \n extracting: data/large/train_large/C_LIQUOR,WINE,BEER.csv  \n extracting: data/large/train_large/C_MAGAZINES.csv  \n extracting: data/large/train_large/C_MEATS.csv  \n extracting: data/large/train_large/C_PERSONAL CARE.csv  \n extracting: data/large/train_large/C_PET SUPPLIES.csv  \n extracting: data/large/train_large/C_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/train_large/C_POULTRY.csv  \n extracting: data/large/train_large/C_PREPARED FOODS.csv  \n extracting: data/large/train_large/C_PRODUCE.csv  \n extracting: data/large/train_large/C_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/train_large/C_SEAFOOD.csv  \n extracting: data/large/train_large/D_AUTOMOTIVE.csv  \n extracting: data/large/train_large/D_BABY CARE.csv  \n extracting: data/large/train_large/D_BEAUTY.csv  \n extracting: data/large/train_large/D_BEVERAGES.csv  \n extracting: data/large/train_large/D_BOOKS.csv  \n extracting: data/large/train_large/D_BREAD_BAKERY.csv  \n extracting: data/large/train_large/D_CELEBRATION.csv  \n extracting: data/large/train_large/D_CLEANING.csv  \n extracting: data/large/train_large/D_DAIRY.csv  \n extracting: data/large/train_large/D_DELI.csv  \n extracting: data/large/train_large/D_EGGS.csv  \n extracting: data/large/train_large/D_FROZEN FOODS.csv  \n extracting: data/large/train_large/D_GROCERY I.csv  \n extracting: data/large/train_large/D_GROCERY II.csv  \n extracting: data/large/train_large/D_HARDWARE.csv  \n extracting: data/large/train_large/D_HOME AND KITCHEN I.csv  \n extracting: data/large/train_large/D_HOME AND KITCHEN II.csv  \n extracting: data/large/train_large/D_HOME APPLIANCES.csv  \n extracting: data/large/train_large/D_HOME CARE.csv  \n extracting: data/large/train_large/D_LADIESWEAR.csv  \n extracting: data/large/train_large/D_LAWN AND GARDEN.csv  \n extracting: data/large/train_large/D_LINGERIE.csv  \n extracting: data/large/train_large/D_LIQUOR,WINE,BEER.csv  \n extracting: data/large/train_large/D_MAGAZINES.csv  \n extracting: data/large/train_large/D_MEATS.csv  \n extracting: data/large/train_large/D_PERSONAL CARE.csv  \n extracting: data/large/train_large/D_PET SUPPLIES.csv  \n extracting: data/large/train_large/D_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/train_large/D_POULTRY.csv  \n extracting: data/large/train_large/D_PREPARED FOODS.csv  \n extracting: data/large/train_large/D_PRODUCE.csv  \n extracting: data/large/train_large/D_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/train_large/D_SEAFOOD.csv  \n extracting: data/large/train_large/E_AUTOMOTIVE.csv  \n extracting: data/large/train_large/E_BABY CARE.csv  \n extracting: data/large/train_large/E_BEAUTY.csv  \n extracting: data/large/train_large/E_BEVERAGES.csv  \n extracting: data/large/train_large/E_BOOKS.csv  \n extracting: data/large/train_large/E_BREAD_BAKERY.csv  \n extracting: data/large/train_large/E_CELEBRATION.csv  \n extracting: data/large/train_large/E_CLEANING.csv  \n extracting: data/large/train_large/E_DAIRY.csv  \n extracting: data/large/train_large/E_DELI.csv  \n extracting: data/large/train_large/E_EGGS.csv  \n extracting: data/large/train_large/E_FROZEN FOODS.csv  \n extracting: data/large/train_large/E_GROCERY I.csv  \n extracting: data/large/train_large/E_GROCERY II.csv  \n extracting: data/large/train_large/E_HARDWARE.csv  \n extracting: data/large/train_large/E_HOME AND KITCHEN I.csv  \n extracting: data/large/train_large/E_HOME AND KITCHEN II.csv  \n extracting: data/large/train_large/E_HOME APPLIANCES.csv  \n extracting: data/large/train_large/E_HOME CARE.csv  \n extracting: data/large/train_large/E_LADIESWEAR.csv  \n extracting: data/large/train_large/E_LAWN AND GARDEN.csv  \n extracting: data/large/train_large/E_LINGERIE.csv  \n extracting: data/large/train_large/E_LIQUOR,WINE,BEER.csv  \n extracting: data/large/train_large/E_MAGAZINES.csv  \n extracting: data/large/train_large/E_MEATS.csv  \n extracting: data/large/train_large/E_PERSONAL CARE.csv  \n extracting: data/large/train_large/E_PET SUPPLIES.csv  \n extracting: data/large/train_large/E_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/train_large/E_POULTRY.csv  \n extracting: data/large/train_large/E_PREPARED FOODS.csv  \n extracting: data/large/train_large/E_PRODUCE.csv  \n extracting: data/large/train_large/E_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/train_large/E_SEAFOOD.csv  \n extracting: data/large/train_large/F_AUTOMOTIVE.csv  \n extracting: data/large/train_large/F_BABY CARE.csv  \n extracting: data/large/train_large/F_BEAUTY.csv  \n extracting: data/large/train_large/F_BEVERAGES.csv  \n extracting: data/large/train_large/F_BOOKS.csv  \n extracting: data/large/train_large/F_BREAD_BAKERY.csv  \n extracting: data/large/train_large/F_CELEBRATION.csv  \n extracting: data/large/train_large/F_CLEANING.csv  \n extracting: data/large/train_large/F_DAIRY.csv  \n extracting: data/large/train_large/F_DELI.csv  \n extracting: data/large/train_large/F_EGGS.csv  \n extracting: data/large/train_large/F_FROZEN FOODS.csv  \n extracting: data/large/train_large/F_GROCERY I.csv  \n extracting: data/large/train_large/F_GROCERY II.csv  \n extracting: data/large/train_large/F_HARDWARE.csv  \n extracting: data/large/train_large/F_HOME AND KITCHEN I.csv  \n extracting: data/large/train_large/F_HOME AND KITCHEN II.csv  \n extracting: data/large/train_large/F_HOME APPLIANCES.csv  \n extracting: data/large/train_large/F_HOME CARE.csv  \n extracting: data/large/train_large/F_LADIESWEAR.csv  \n extracting: data/large/train_large/F_LAWN AND GARDEN.csv  \n extracting: data/large/train_large/F_LINGERIE.csv  \n extracting: data/large/train_large/F_LIQUOR,WINE,BEER.csv  \n extracting: data/large/train_large/F_MAGAZINES.csv  \n extracting: data/large/train_large/F_MEATS.csv  \n extracting: data/large/train_large/F_PERSONAL CARE.csv  \n extracting: data/large/train_large/F_PET SUPPLIES.csv  \n extracting: data/large/train_large/F_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/train_large/F_POULTRY.csv  \n extracting: data/large/train_large/F_PREPARED FOODS.csv  \n extracting: data/large/train_large/F_PRODUCE.csv  \n extracting: data/large/train_large/F_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/train_large/F_SEAFOOD.csv  \n extracting: data/large/train_large/G_AUTOMOTIVE.csv  \n extracting: data/large/train_large/G_BABY CARE.csv  \n extracting: data/large/train_large/G_BEAUTY.csv  \n extracting: data/large/train_large/G_BEVERAGES.csv  \n extracting: data/large/train_large/G_BOOKS.csv  \n extracting: data/large/train_large/G_BREAD_BAKERY.csv  \n extracting: data/large/train_large/G_CELEBRATION.csv  \n extracting: data/large/train_large/G_CLEANING.csv  \n extracting: data/large/train_large/G_DAIRY.csv  \n extracting: data/large/train_large/G_DELI.csv  \n extracting: data/large/train_large/G_EGGS.csv  \n extracting: data/large/train_large/G_FROZEN FOODS.csv  \n extracting: data/large/train_large/G_GROCERY I.csv  \n extracting: data/large/train_large/G_GROCERY II.csv  \n extracting: data/large/train_large/G_HARDWARE.csv  \n extracting: data/large/train_large/G_HOME AND KITCHEN I.csv  \n extracting: data/large/train_large/G_HOME AND KITCHEN II.csv  \n extracting: data/large/train_large/G_HOME APPLIANCES.csv  \n extracting: data/large/train_large/G_HOME CARE.csv  \n extracting: data/large/train_large/G_LADIESWEAR.csv  \n extracting: data/large/train_large/G_LAWN AND GARDEN.csv  \n extracting: data/large/train_large/G_LINGERIE.csv  \n extracting: data/large/train_large/G_LIQUOR,WINE,BEER.csv  \n extracting: data/large/train_large/G_MAGAZINES.csv  \n extracting: data/large/train_large/G_MEATS.csv  \n extracting: data/large/train_large/G_PERSONAL CARE.csv  \n extracting: data/large/train_large/G_PET SUPPLIES.csv  \n extracting: data/large/train_large/G_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/train_large/G_POULTRY.csv  \n extracting: data/large/train_large/G_PREPARED FOODS.csv  \n extracting: data/large/train_large/G_PRODUCE.csv  \n extracting: data/large/train_large/G_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/train_large/G_SEAFOOD.csv  \n extracting: data/large/train_large/H_AUTOMOTIVE.csv  \n extracting: data/large/train_large/H_BABY CARE.csv  \n extracting: data/large/train_large/H_BEAUTY.csv  \n extracting: data/large/train_large/H_BEVERAGES.csv  \n extracting: data/large/train_large/H_BOOKS.csv  \n extracting: data/large/train_large/H_BREAD_BAKERY.csv  \n extracting: data/large/train_large/H_CELEBRATION.csv  \n extracting: data/large/train_large/H_CLEANING.csv  \n extracting: data/large/train_large/H_DAIRY.csv  \n extracting: data/large/train_large/H_DELI.csv  \n extracting: data/large/train_large/H_EGGS.csv  \n extracting: data/large/train_large/H_FROZEN FOODS.csv  \n extracting: data/large/train_large/H_GROCERY I.csv  \n extracting: data/large/train_large/H_GROCERY II.csv  \n extracting: data/large/train_large/H_HARDWARE.csv  \n extracting: data/large/train_large/H_HOME AND KITCHEN I.csv  \n extracting: data/large/train_large/H_HOME AND KITCHEN II.csv  \n extracting: data/large/train_large/H_HOME APPLIANCES.csv  \n extracting: data/large/train_large/H_HOME CARE.csv  \n extracting: data/large/train_large/H_LADIESWEAR.csv  \n extracting: data/large/train_large/H_LAWN AND GARDEN.csv  \n extracting: data/large/train_large/H_LINGERIE.csv  \n extracting: data/large/train_large/H_LIQUOR,WINE,BEER.csv  \n extracting: data/large/train_large/H_MAGAZINES.csv  \n extracting: data/large/train_large/H_MEATS.csv  \n extracting: data/large/train_large/H_PERSONAL CARE.csv  \n extracting: data/large/train_large/H_PET SUPPLIES.csv  \n extracting: data/large/train_large/H_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/train_large/H_POULTRY.csv  \n extracting: data/large/train_large/H_PREPARED FOODS.csv  \n extracting: data/large/train_large/H_PRODUCE.csv  \n extracting: data/large/train_large/H_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/train_large/H_SEAFOOD.csv  \n extracting: data/large/train_large/I_AUTOMOTIVE.csv  \n extracting: data/large/train_large/I_BABY CARE.csv  \n extracting: data/large/train_large/I_BEAUTY.csv  \n extracting: data/large/train_large/I_BEVERAGES.csv  \n extracting: data/large/train_large/I_BOOKS.csv  \n extracting: data/large/train_large/I_BREAD_BAKERY.csv  \n extracting: data/large/train_large/I_CELEBRATION.csv  \n extracting: data/large/train_large/I_CLEANING.csv  \n extracting: data/large/train_large/I_DAIRY.csv  \n extracting: data/large/train_large/I_DELI.csv  \n extracting: data/large/train_large/I_EGGS.csv  \n extracting: data/large/train_large/I_FROZEN FOODS.csv  \n extracting: data/large/train_large/I_GROCERY I.csv  \n extracting: data/large/train_large/I_GROCERY II.csv  \n extracting: data/large/train_large/I_HARDWARE.csv  \n extracting: data/large/train_large/I_HOME AND KITCHEN I.csv  \n extracting: data/large/train_large/I_HOME AND KITCHEN II.csv  \n extracting: data/large/train_large/I_HOME APPLIANCES.csv  \n extracting: data/large/train_large/I_HOME CARE.csv  \n extracting: data/large/train_large/I_LADIESWEAR.csv  \n extracting: data/large/train_large/I_LAWN AND GARDEN.csv  \n extracting: data/large/train_large/I_LINGERIE.csv  \n extracting: data/large/train_large/I_LIQUOR,WINE,BEER.csv  \n extracting: data/large/train_large/I_MAGAZINES.csv  \n extracting: data/large/train_large/I_MEATS.csv  \n extracting: data/large/train_large/I_PERSONAL CARE.csv  \n extracting: data/large/train_large/I_PET SUPPLIES.csv  \n extracting: data/large/train_large/I_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/train_large/I_POULTRY.csv  \n extracting: data/large/train_large/I_PREPARED FOODS.csv  \n extracting: data/large/train_large/I_PRODUCE.csv  \n extracting: data/large/train_large/I_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/train_large/I_SEAFOOD.csv  \n extracting: data/large/train_large/J_AUTOMOTIVE.csv  \n extracting: data/large/train_large/J_BABY CARE.csv  \n extracting: data/large/train_large/J_BEAUTY.csv  \n extracting: data/large/train_large/J_BEVERAGES.csv  \n extracting: data/large/train_large/J_BOOKS.csv  \n extracting: data/large/train_large/J_BREAD_BAKERY.csv  \n extracting: data/large/train_large/J_CELEBRATION.csv  \n extracting: data/large/train_large/J_CLEANING.csv  \n extracting: data/large/train_large/J_DAIRY.csv  \n extracting: data/large/train_large/J_DELI.csv  \n extracting: data/large/train_large/J_EGGS.csv  \n extracting: data/large/train_large/J_FROZEN FOODS.csv  \n extracting: data/large/train_large/J_GROCERY I.csv  \n extracting: data/large/train_large/J_GROCERY II.csv  \n extracting: data/large/train_large/J_HARDWARE.csv  \n extracting: data/large/train_large/J_HOME AND KITCHEN I.csv  \n extracting: data/large/train_large/J_HOME AND KITCHEN II.csv  \n extracting: data/large/train_large/J_HOME APPLIANCES.csv  \n extracting: data/large/train_large/J_HOME CARE.csv  \n extracting: data/large/train_large/J_LADIESWEAR.csv  \n extracting: data/large/train_large/J_LAWN AND GARDEN.csv  \n extracting: data/large/train_large/J_LINGERIE.csv  \n extracting: data/large/train_large/J_LIQUOR,WINE,BEER.csv  \n extracting: data/large/train_large/J_MAGAZINES.csv  \n extracting: data/large/train_large/J_MEATS.csv  \n extracting: data/large/train_large/J_PERSONAL CARE.csv  \n extracting: data/large/train_large/J_PET SUPPLIES.csv  \n extracting: data/large/train_large/J_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/train_large/J_POULTRY.csv  \n extracting: data/large/train_large/J_PREPARED FOODS.csv  \n extracting: data/large/train_large/J_PRODUCE.csv  \n extracting: data/large/train_large/J_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/train_large/J_SEAFOOD.csv  \n extracting: data/large/train_large/K_AUTOMOTIVE.csv  \n extracting: data/large/train_large/K_BABY CARE.csv  \n extracting: data/large/train_large/K_BEAUTY.csv  \n extracting: data/large/train_large/K_BEVERAGES.csv  \n extracting: data/large/train_large/K_BOOKS.csv  \n extracting: data/large/train_large/K_BREAD_BAKERY.csv  \n extracting: data/large/train_large/K_CELEBRATION.csv  \n extracting: data/large/train_large/K_CLEANING.csv  \n extracting: data/large/train_large/K_DAIRY.csv  \n extracting: data/large/train_large/K_DELI.csv  \n extracting: data/large/train_large/K_EGGS.csv  \n extracting: data/large/train_large/K_FROZEN FOODS.csv  \n extracting: data/large/train_large/K_GROCERY I.csv  \n extracting: data/large/train_large/K_GROCERY II.csv  \n extracting: data/large/train_large/K_HARDWARE.csv  \n extracting: data/large/train_large/K_HOME AND KITCHEN I.csv  \n extracting: data/large/train_large/K_HOME AND KITCHEN II.csv  \n extracting: data/large/train_large/K_HOME APPLIANCES.csv  \n extracting: data/large/train_large/K_HOME CARE.csv  \n extracting: data/large/train_large/K_LADIESWEAR.csv  \n extracting: data/large/train_large/K_LAWN AND GARDEN.csv  \n extracting: data/large/train_large/K_LINGERIE.csv  \n extracting: data/large/train_large/K_LIQUOR,WINE,BEER.csv  \n extracting: data/large/train_large/K_MAGAZINES.csv  \n extracting: data/large/train_large/K_MEATS.csv  \n extracting: data/large/train_large/K_PERSONAL CARE.csv  \n extracting: data/large/train_large/K_PET SUPPLIES.csv  \n extracting: data/large/train_large/K_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/train_large/K_POULTRY.csv  \n extracting: data/large/train_large/K_PREPARED FOODS.csv  \n extracting: data/large/train_large/K_PRODUCE.csv  \n extracting: data/large/train_large/K_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/train_large/K_SEAFOOD.csv  \n extracting: data/large/train_large/L_AUTOMOTIVE.csv  \n extracting: data/large/train_large/L_BABY CARE.csv  \n extracting: data/large/train_large/L_BEAUTY.csv  \n extracting: data/large/train_large/L_BEVERAGES.csv  \n extracting: data/large/train_large/L_BOOKS.csv  \n extracting: data/large/train_large/L_BREAD_BAKERY.csv  \n extracting: data/large/train_large/L_CELEBRATION.csv  \n extracting: data/large/train_large/L_CLEANING.csv  \n extracting: data/large/train_large/L_DAIRY.csv  \n extracting: data/large/train_large/L_DELI.csv  \n extracting: data/large/train_large/L_EGGS.csv  \n extracting: data/large/train_large/L_FROZEN FOODS.csv  \n extracting: data/large/train_large/L_GROCERY I.csv  \n extracting: data/large/train_large/L_GROCERY II.csv  \n extracting: data/large/train_large/L_HARDWARE.csv  \n extracting: data/large/train_large/L_HOME AND KITCHEN I.csv  \n extracting: data/large/train_large/L_HOME AND KITCHEN II.csv  \n extracting: data/large/train_large/L_HOME APPLIANCES.csv  \n extracting: data/large/train_large/L_HOME CARE.csv  \n extracting: data/large/train_large/L_LADIESWEAR.csv  \n extracting: data/large/train_large/L_LAWN AND GARDEN.csv  \n extracting: data/large/train_large/L_LINGERIE.csv  \n extracting: data/large/train_large/L_LIQUOR,WINE,BEER.csv  \n extracting: data/large/train_large/L_MAGAZINES.csv  \n extracting: data/large/train_large/L_MEATS.csv  \n extracting: data/large/train_large/L_PERSONAL CARE.csv  \n extracting: data/large/train_large/L_PET SUPPLIES.csv  \n extracting: data/large/train_large/L_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/train_large/L_POULTRY.csv  \n extracting: data/large/train_large/L_PREPARED FOODS.csv  \n extracting: data/large/train_large/L_PRODUCE.csv  \n extracting: data/large/train_large/L_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/train_large/L_SEAFOOD.csv  \n extracting: data/large/train_large/M_AUTOMOTIVE.csv  \n extracting: data/large/train_large/M_BABY CARE.csv  \n extracting: data/large/train_large/M_BEAUTY.csv  \n extracting: data/large/train_large/M_BEVERAGES.csv  \n extracting: data/large/train_large/M_BOOKS.csv  \n extracting: data/large/train_large/M_BREAD_BAKERY.csv  \n extracting: data/large/train_large/M_CELEBRATION.csv  \n extracting: data/large/train_large/M_CLEANING.csv  \n extracting: data/large/train_large/M_DAIRY.csv  \n extracting: data/large/train_large/M_DELI.csv  \n extracting: data/large/train_large/M_EGGS.csv  \n extracting: data/large/train_large/M_FROZEN FOODS.csv  \n extracting: data/large/train_large/M_GROCERY I.csv  \n extracting: data/large/train_large/M_GROCERY II.csv  \n extracting: data/large/train_large/M_HARDWARE.csv  \n extracting: data/large/train_large/M_HOME AND KITCHEN I.csv  \n extracting: data/large/train_large/M_HOME AND KITCHEN II.csv  \n extracting: data/large/train_large/M_HOME APPLIANCES.csv  \n extracting: data/large/train_large/M_HOME CARE.csv  \n extracting: data/large/train_large/M_LADIESWEAR.csv  \n extracting: data/large/train_large/M_LAWN AND GARDEN.csv  \n extracting: data/large/train_large/M_LINGERIE.csv  \n extracting: data/large/train_large/M_LIQUOR,WINE,BEER.csv  \n extracting: data/large/train_large/M_MAGAZINES.csv  \n extracting: data/large/train_large/M_MEATS.csv  \n extracting: data/large/train_large/M_PERSONAL CARE.csv  \n extracting: data/large/train_large/M_PET SUPPLIES.csv  \n extracting: data/large/train_large/M_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/train_large/M_POULTRY.csv  \n extracting: data/large/train_large/M_PREPARED FOODS.csv  \n extracting: data/large/train_large/M_PRODUCE.csv  \n extracting: data/large/train_large/M_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/train_large/M_SEAFOOD.csv  \n extracting: data/large/train_large/N_AUTOMOTIVE.csv  \n extracting: data/large/train_large/N_BABY CARE.csv  \n extracting: data/large/train_large/N_BEAUTY.csv  \n extracting: data/large/train_large/N_BEVERAGES.csv  \n extracting: data/large/train_large/N_BOOKS.csv  \n extracting: data/large/train_large/N_BREAD_BAKERY.csv  \n extracting: data/large/train_large/N_CELEBRATION.csv  \n extracting: data/large/train_large/N_CLEANING.csv  \n extracting: data/large/train_large/N_DAIRY.csv  \n extracting: data/large/train_large/N_DELI.csv  \n extracting: data/large/train_large/N_EGGS.csv  \n extracting: data/large/train_large/N_FROZEN FOODS.csv  \n extracting: data/large/train_large/N_GROCERY I.csv  \n extracting: data/large/train_large/N_GROCERY II.csv  \n extracting: data/large/train_large/N_HARDWARE.csv  \n extracting: data/large/train_large/N_HOME AND KITCHEN I.csv  \n extracting: data/large/train_large/N_HOME AND KITCHEN II.csv  \n extracting: data/large/train_large/N_HOME APPLIANCES.csv  \n extracting: data/large/train_large/N_HOME CARE.csv  \n extracting: data/large/train_large/N_LADIESWEAR.csv  \n extracting: data/large/train_large/N_LAWN AND GARDEN.csv  \n extracting: data/large/train_large/N_LINGERIE.csv  \n extracting: data/large/train_large/N_LIQUOR,WINE,BEER.csv  \n extracting: data/large/train_large/N_MAGAZINES.csv  \n extracting: data/large/train_large/N_MEATS.csv  \n extracting: data/large/train_large/N_PERSONAL CARE.csv  \n extracting: data/large/train_large/N_PET SUPPLIES.csv  \n extracting: data/large/train_large/N_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/train_large/N_POULTRY.csv  \n extracting: data/large/train_large/N_PREPARED FOODS.csv  \n extracting: data/large/train_large/N_PRODUCE.csv  \n extracting: data/large/train_large/N_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/train_large/N_SEAFOOD.csv  \n extracting: data/large/train_large/O_AUTOMOTIVE.csv  \n extracting: data/large/train_large/O_BABY CARE.csv  \n extracting: data/large/train_large/O_BEAUTY.csv  \n extracting: data/large/train_large/O_BEVERAGES.csv  \n extracting: data/large/train_large/O_BOOKS.csv  \n extracting: data/large/train_large/O_BREAD_BAKERY.csv  \n extracting: data/large/train_large/O_CELEBRATION.csv  \n extracting: data/large/train_large/O_CLEANING.csv  \n extracting: data/large/train_large/O_DAIRY.csv  \n extracting: data/large/train_large/O_DELI.csv  \n extracting: data/large/train_large/O_EGGS.csv  \n extracting: data/large/train_large/O_FROZEN FOODS.csv  \n extracting: data/large/train_large/O_GROCERY I.csv  \n extracting: data/large/train_large/O_GROCERY II.csv  \n extracting: data/large/train_large/O_HARDWARE.csv  \n extracting: data/large/train_large/O_HOME AND KITCHEN I.csv  \n extracting: data/large/train_large/O_HOME AND KITCHEN II.csv  \n extracting: data/large/train_large/O_HOME APPLIANCES.csv  \n extracting: data/large/train_large/O_HOME CARE.csv  \n extracting: data/large/train_large/O_LADIESWEAR.csv  \n extracting: data/large/train_large/O_LAWN AND GARDEN.csv  \n extracting: data/large/train_large/O_LINGERIE.csv  \n extracting: data/large/train_large/O_LIQUOR,WINE,BEER.csv  \n extracting: data/large/train_large/O_MAGAZINES.csv  \n extracting: data/large/train_large/O_MEATS.csv  \n extracting: data/large/train_large/O_PERSONAL CARE.csv  \n extracting: data/large/train_large/O_PET SUPPLIES.csv  \n extracting: data/large/train_large/O_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/train_large/O_POULTRY.csv  \n extracting: data/large/train_large/O_PREPARED FOODS.csv  \n extracting: data/large/train_large/O_PRODUCE.csv  \n extracting: data/large/train_large/O_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/train_large/O_SEAFOOD.csv  \n extracting: data/large/train_large/P_AUTOMOTIVE.csv  \n extracting: data/large/train_large/P_BABY CARE.csv  \n extracting: data/large/train_large/P_BEAUTY.csv  \n extracting: data/large/train_large/P_BEVERAGES.csv  \n extracting: data/large/train_large/P_BOOKS.csv  \n extracting: data/large/train_large/P_BREAD_BAKERY.csv  \n extracting: data/large/train_large/P_CELEBRATION.csv  \n extracting: data/large/train_large/P_CLEANING.csv  \n extracting: data/large/train_large/P_DAIRY.csv  \n extracting: data/large/train_large/P_DELI.csv  \n extracting: data/large/train_large/P_EGGS.csv  \n extracting: data/large/train_large/P_FROZEN FOODS.csv  \n extracting: data/large/train_large/P_GROCERY I.csv  \n extracting: data/large/train_large/P_GROCERY II.csv  \n extracting: data/large/train_large/P_HARDWARE.csv  \n extracting: data/large/train_large/P_HOME AND KITCHEN I.csv  \n extracting: data/large/train_large/P_HOME AND KITCHEN II.csv  \n extracting: data/large/train_large/P_HOME APPLIANCES.csv  \n extracting: data/large/train_large/P_HOME CARE.csv  \n extracting: data/large/train_large/P_LADIESWEAR.csv  \n extracting: data/large/train_large/P_LAWN AND GARDEN.csv  \n extracting: data/large/train_large/P_LINGERIE.csv  \n extracting: data/large/train_large/P_LIQUOR,WINE,BEER.csv  \n extracting: data/large/train_large/P_MAGAZINES.csv  \n extracting: data/large/train_large/P_MEATS.csv  \n extracting: data/large/train_large/P_PERSONAL CARE.csv  \n extracting: data/large/train_large/P_PET SUPPLIES.csv  \n extracting: data/large/train_large/P_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/train_large/P_POULTRY.csv  \n extracting: data/large/train_large/P_PREPARED FOODS.csv  \n extracting: data/large/train_large/P_PRODUCE.csv  \n extracting: data/large/train_large/P_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/train_large/P_SEAFOOD.csv  \n extracting: data/large/train_large/Q_AUTOMOTIVE.csv  \n extracting: data/large/train_large/Q_BABY CARE.csv  \n extracting: data/large/train_large/Q_BEAUTY.csv  \n extracting: data/large/train_large/Q_BEVERAGES.csv  \n extracting: data/large/train_large/Q_BOOKS.csv  \n extracting: data/large/train_large/Q_BREAD_BAKERY.csv  \n extracting: data/large/train_large/Q_CELEBRATION.csv  \n extracting: data/large/train_large/Q_CLEANING.csv  \n extracting: data/large/train_large/Q_DAIRY.csv  \n extracting: data/large/train_large/Q_DELI.csv  \n extracting: data/large/train_large/Q_EGGS.csv  \n extracting: data/large/train_large/Q_FROZEN FOODS.csv  \n extracting: data/large/train_large/Q_GROCERY I.csv  \n extracting: data/large/train_large/Q_GROCERY II.csv  \n extracting: data/large/train_large/Q_HARDWARE.csv  \n extracting: data/large/train_large/Q_HOME AND KITCHEN I.csv  \n extracting: data/large/train_large/Q_HOME AND KITCHEN II.csv  \n extracting: data/large/train_large/Q_HOME APPLIANCES.csv  \n extracting: data/large/train_large/Q_HOME CARE.csv  \n extracting: data/large/train_large/Q_LADIESWEAR.csv  \n extracting: data/large/train_large/Q_LAWN AND GARDEN.csv  \n extracting: data/large/train_large/Q_LINGERIE.csv  \n extracting: data/large/train_large/Q_LIQUOR,WINE,BEER.csv  \n extracting: data/large/train_large/Q_MAGAZINES.csv  \n extracting: data/large/train_large/Q_MEATS.csv  \n extracting: data/large/train_large/Q_PERSONAL CARE.csv  \n extracting: data/large/train_large/Q_PET SUPPLIES.csv  \n extracting: data/large/train_large/Q_PLAYERS AND ELECTRONICS.csv  \n extracting: data/large/train_large/Q_POULTRY.csv  \n extracting: data/large/train_large/Q_PREPARED FOODS.csv  \n extracting: data/large/train_large/Q_PRODUCE.csv  \n extracting: data/large/train_large/Q_SCHOOL AND OFFICE SUPPLIES.csv  \n extracting: data/large/train_large/Q_SEAFOOD.csv  \n","output_type":"stream"}]},{"cell_type":"code","source":"!ls data","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:18:39.533926Z","iopub.execute_input":"2022-06-26T10:18:39.534896Z","iopub.status.idle":"2022-06-26T10:18:40.324445Z","shell.execute_reply.started":"2022-06-26T10:18:39.534849Z","shell.execute_reply":"2022-06-26T10:18:40.323212Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"large  small\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# The Functions\n","metadata":{}},{"cell_type":"markdown","source":"Here are the functions we created in the previous notebook. We will be creating some more functions to make our life easier.\n","metadata":{}},{"cell_type":"code","source":"def merge_dataframes(file, log_sale=False, large=True):\n    \"\"\"\n    Takes the file name of the dataframe merges the train and test dataframe into one dataframe\n    also does some transformations to the dataframe\n\n    Parameters\n    ----------\n    file : str\n        The file name of the dataframe\n    log_sale : bool\n        Whether to log the sale price or not\n\n    Returns\n    -------\n    (dataframe, dataframe, dataframe), dataframe\n        ((train_data, test_data, y_train), test_indices)\n    \"\"\"\n    if large:\n        train_data_dir = os.path.join(\"data\", \"large\", \"train_large\")\n        test_data_dir = os.path.join(\"data\", \"large\", \"test_large\")\n    else:\n        train_data_dir = os.path.join(\"data\", \"small\", \"train\")\n        test_data_dir = os.path.join(\"data\", \"small\", \"test\")\n    train_data = pd.read_csv(os.path.join(train_data_dir, file)).set_index(\"id\")\n    test_data = pd.read_csv(os.path.join(test_data_dir, file)).set_index(\"id\")\n\n    train_indices = train_data.index\n    test_indices = test_data.index\n    y_train = train_data.sales.values\n\n    merged_df = pd.concat([train_data, test_data], axis=0)\n    if large:\n        cols_to_drop = [\"date\", \"sales\", \"store_nbr\",]\n    else:\n        cols_to_drop = [\"date\", \"sales\"]\n    merged_df = merged_df.drop(cols_to_drop, axis=1)\n    merged_indices = merged_df.index\n\n    one_hot_cols = merged_df.columns[\n        (merged_df.dtypes == \"object\") | (merged_df.dtypes == \"bool\")\n    ]\n    one_hot_encoder = OneHotEncoder(sparse=False, handle_unknown=\"error\", drop=\"first\")\n    column_transformer = ColumnTransformer(\n        [\n            (\"categorical_cols\", one_hot_encoder, one_hot_cols),\n        ],\n        remainder=\"passthrough\",\n    )\n    if log_sale:\n        y_train = np.log(y_train + 1)\n\n    merged_df = column_transformer.fit_transform(merged_df)\n    merged_df = pd.DataFrame(merged_df, index=merged_indices)\n    train_data = merged_df.loc[train_indices]\n    test_data = merged_df.loc[test_indices]\n    return (train_data, test_data, y_train), test_indices\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:36:49.057069Z","iopub.execute_input":"2022-06-26T10:36:49.057464Z","iopub.status.idle":"2022-06-26T10:36:49.071322Z","shell.execute_reply.started":"2022-06-26T10:36:49.057435Z","shell.execute_reply":"2022-06-26T10:36:49.070495Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"def create_train_test(X, y, ratio=0.8):\n    \"\"\"\n    Creates the train test split\n\n    Parameters\n    ----------\n    X : dataframe\n        The dataframe to split\n    y : dataframe\n        The target dataframe\n    ratio : float\n        The ratio of the train data to the test data\n\n    Returns\n    -------\n    (dataframe, dataframe, dataframe, dataframe)\n        (X_train, y_train, X_test, y_test)\n    \"\"\"\n    X = X.values\n    X_train = X[:int(len(X) * ratio)]\n    y_train = y[:int(len(y) * ratio)]\n    X_test = X[int(len(X) * ratio):]\n    y_test = y[int(len(y) * ratio):]\n    return X_train, y_train, X_test, y_test\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:21:19.237949Z","iopub.execute_input":"2022-06-26T10:21:19.238335Z","iopub.status.idle":"2022-06-26T10:21:19.244759Z","shell.execute_reply.started":"2022-06-26T10:21:19.238302Z","shell.execute_reply":"2022-06-26T10:21:19.243644Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def evaluate(\n    model, data=None, on=\"test\", log_sale=False, return_preds=False, no_print=False\n):\n    \"\"\"\n    Evaluates the model on the test data or the train data\n\n    Parameters\n    ----------\n    model : sklearn model\n        The model to evaluate\n    on : str\n        The data to evaluate on\n    log_sale : bool\n        Whether to log the sale price or not\n    return_preds : bool\n        Whether to return the predictions or not\n\n    Returns\n    -------\n    (dict, dataframe)|(dataframe)\n        (metrics, y_pred) or y_pred\n    \"\"\"\n    if data is None:\n        if on == \"test\":\n            X = X_test\n            y = y_test\n        elif on == \"train\":\n            X = X_train\n            y = y_train\n    else:\n        X = data[0]\n        y = data[1]\n    # print(\"Predicting\")\n    preds = model.predict(X)\n    if log_sale:\n        # print(\"Exponentiating\")\n        preds = np.exp(preds) - 1\n        y = np.exp(y) - 1\n    # print(\"Calculating Metrics\")\n    mse = mean_squared_error(y, preds)\n    mae = mean_absolute_error(y, preds)\n    try:\n        msle = mean_squared_log_error(y, preds)\n    except:\n        preds = np.abs(preds)\n        msle = mean_squared_log_error(y, preds)\n    rmse = np.sqrt(msle)\n    r2_value = r2_score(y, preds)\n    if not no_print:\n        print(\"MSE:\", mse)\n        print(\"MAE:\", mae)\n        print(\"MSLE:\", msle)\n        print(\"RMSE:\", rmse)\n        print(\"R2:\", r2_value)\n\n    metrics = {\"mse\": mse, \"mae\": mae, \"msle\": msle, \"rmse\": rmse, \"r2\": r2_value}\n    if return_preds:\n        return metrics, preds\n    else:\n        return metrics\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:21:21.235566Z","iopub.execute_input":"2022-06-26T10:21:21.236222Z","iopub.status.idle":"2022-06-26T10:21:21.246463Z","shell.execute_reply.started":"2022-06-26T10:21:21.236172Z","shell.execute_reply":"2022-06-26T10:21:21.245726Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def create_pred_dataframe(X, model, id=None, log_sale=False):\n    \"\"\"\n    Creates a dataframe of the predictions\n\n    Parameters\n    ----------\n    X : dataframe\n        The dataframe to predict on\n    model : sklearn model\n        The model to predict with\n    id : str\n        The id of the dataframe\n    log_sale : bool\n        Whether to log the sale price or not\n\n    Returns\n    -------\n    dataframe\n        The dataframe of the predictions\n    \"\"\"\n    preds = model.predict(X)\n    if log_sale:\n        preds = np.exp(preds) - 1\n    if id is None:\n        id = np.arange(len(preds))\n    df = pd.DataFrame(preds, columns=[\"sales\"])\n    df = pd.DataFrame(id, columns=[\"id\"])\n    df[\"sales\"] = preds\n    df.reset_index(drop=True, inplace=True)\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:21:23.230578Z","iopub.execute_input":"2022-06-26T10:21:23.230952Z","iopub.status.idle":"2022-06-26T10:21:23.238328Z","shell.execute_reply.started":"2022-06-26T10:21:23.230921Z","shell.execute_reply":"2022-06-26T10:21:23.237082Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def train_and_evaluate(\n    model, file, log_sale=False, return_preds=True, on=\"test\", no_print=False, large=True\n):\n    (train_data, test_data, y), test_indices = merge_dataframes(file, large=large)\n    X_train, y_train, X_test, y_test = create_train_test(train_data, y)\n    model.fit(X_train, y_train)\n    if on == \"test\":\n        data = (X_test, y_test)\n    elif on == \"train\":\n        data = (X_train, y_train)\n    if return_preds:\n        metrics, preds = evaluate(\n            model,\n            data=data,\n            on=on,\n            log_sale=log_sale,\n            return_preds=return_preds,\n            no_print=no_print,\n        )\n    else:\n        metrics = evaluate(\n            model,\n            data=data,\n            on=on,\n            log_sale=log_sale,\n            return_preds=return_preds,\n            no_print=no_print,\n        )\n        preds = None\n    return metrics, preds\n\n\ndef train_evaluate_and_save(model_name, files, data=\"test\", **kwargs):\n    i = 0\n    for file in tqdm.tqdm(files, desc=\"Training and Evaluating\"):\n        name = model_name + \"_\" + str(i)\n        # print(\"Performance for:\", file)\n        metrics, _ = train_and_evaluate(file=file, **kwargs)\n        # print(\"\\n\")\n        if data == \"test\":\n            performace_on_test[name] = metrics\n        else:\n            performace_on_train[name] = metrics\n        i += 1\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:07:34.900912Z","iopub.execute_input":"2022-06-26T11:07:34.901360Z","iopub.status.idle":"2022-06-26T11:07:34.911598Z","shell.execute_reply.started":"2022-06-26T11:07:34.901327Z","shell.execute_reply":"2022-06-26T11:07:34.910768Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"def train_and_predict(model, file):\n    (train_data, test_data, y), test_indices = merge_dataframes(file)\n    X_train, y_train, X_test, y_test = create_train_test(train_data, y)\n    model.fit(X_train, y_train)\n    df = create_pred_dataframe(test_data, model, id=test_indices, log_sale=False)\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:21:27.659215Z","iopub.execute_input":"2022-06-26T10:21:27.660097Z","iopub.status.idle":"2022-06-26T10:21:27.664594Z","shell.execute_reply.started":"2022-06-26T10:21:27.660059Z","shell.execute_reply":"2022-06-26T10:21:27.663838Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Models\n","metadata":{}},{"cell_type":"markdown","source":"## How To Proceed\n","metadata":{}},{"cell_type":"markdown","source":"We have 88 dataframes for the *small* dataset and 561 for the *large*. This means that searching for the best model for each model might not possible. That's why we'll be using 15 different datasets to train and evaluate models. The model performing the best on these three datasets will be used as a final model. First we'll do this for the *small* datasets.\n","metadata":{}},{"cell_type":"markdown","source":"## Small Dataset","metadata":{}},{"cell_type":"code","source":"random.seed(42)\nTRAIN_DIR = \"data/small/train\"\nTEST_DIR = \"data/small/test\"\n\nall_files = os.listdir(TRAIN_DIR)\nsample_files = random.sample(all_files, 15)\nsample_files","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:25:06.750571Z","iopub.execute_input":"2022-06-26T10:25:06.750985Z","iopub.status.idle":"2022-06-26T10:25:06.760287Z","shell.execute_reply.started":"2022-06-26T10:25:06.750950Z","shell.execute_reply":"2022-06-26T10:25:06.759461Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"['G_LADIES.csv',\n 'C_HOUSEHOLD.csv',\n 'I_HOUSEHOLD.csv',\n 'B_GROCERY.csv',\n 'I_MISC.csv',\n 'Z_GROCERY.csv',\n 'G_HOUSEHOLD.csv',\n 'I_FOOD.csv',\n 'G_MISC.csv',\n 'J_HOUSEHOLD.csv',\n 'J_STATIONARY.csv',\n 'H_BEVERAGE.csv',\n 'H_LADIES.csv',\n 'F_GROCERY.csv',\n 'J_ELECTRONICS.csv']"},"metadata":{}}]},{"cell_type":"code","source":"len(all_files)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:25:11.428644Z","iopub.execute_input":"2022-06-26T10:25:11.429977Z","iopub.status.idle":"2022-06-26T10:25:11.436949Z","shell.execute_reply.started":"2022-06-26T10:25:11.429925Z","shell.execute_reply":"2022-06-26T10:25:11.435729Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"88"},"metadata":{}}]},{"cell_type":"markdown","source":"### The Base Model","metadata":{}},{"cell_type":"code","source":"!ls data/large","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:26:05.142372Z","iopub.execute_input":"2022-06-26T10:26:05.142782Z","iopub.status.idle":"2022-06-26T10:26:05.945920Z","shell.execute_reply.started":"2022-06-26T10:26:05.142751Z","shell.execute_reply":"2022-06-26T10:26:05.944796Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"test_large  train_large\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The linear model with default parameters will be our base model.\n","metadata":{}},{"cell_type":"code","source":"lr = LinearRegression()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:08:03.406207Z","iopub.execute_input":"2022-06-26T11:08:03.406620Z","iopub.status.idle":"2022-06-26T11:08:03.411814Z","shell.execute_reply.started":"2022-06-26T11:08:03.406579Z","shell.execute_reply":"2022-06-26T11:08:03.410541Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"performace_on_test = {}\ntrain_evaluate_and_save(\"lr1\", sample_files, data=\"test\", on=\"test\", model=lr, no_print=True, large=False)\npd.DataFrame(performace_on_test).T.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:08:06.810629Z","iopub.execute_input":"2022-06-26T11:08:06.811044Z","iopub.status.idle":"2022-06-26T11:08:08.815445Z","shell.execute_reply.started":"2022-06-26T11:08:06.811013Z","shell.execute_reply":"2022-06-26T11:08:08.813946Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stderr","text":"Training and Evaluating: 100%|██████████| 15/15 [00:01<00:00,  7.71it/s]\n","output_type":"stream"},{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"                mse          mae       msle       rmse         r2\ncount  1.500000e+01    15.000000  15.000000  15.000000  15.000000\nmean   2.659221e+06   804.080717   6.576132   2.281650  -0.070693\nstd    3.566972e+06   760.203159   7.688913   1.211642   0.787876\nmin    3.490122e+01     3.760181   1.090414   1.044229  -2.027237\n25%    8.831388e+04   182.707047   2.464969   1.568044  -0.000756\n50%    1.066441e+06   674.208648   3.816975   1.953708   0.146233\n75%    4.865453e+06  1431.583123   6.416486   2.532814   0.358035\nmax    1.094965e+07  2199.494702  26.247583   5.123240   0.657434","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mse</th>\n      <th>mae</th>\n      <th>msle</th>\n      <th>rmse</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.500000e+01</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.659221e+06</td>\n      <td>804.080717</td>\n      <td>6.576132</td>\n      <td>2.281650</td>\n      <td>-0.070693</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.566972e+06</td>\n      <td>760.203159</td>\n      <td>7.688913</td>\n      <td>1.211642</td>\n      <td>0.787876</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>3.490122e+01</td>\n      <td>3.760181</td>\n      <td>1.090414</td>\n      <td>1.044229</td>\n      <td>-2.027237</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>8.831388e+04</td>\n      <td>182.707047</td>\n      <td>2.464969</td>\n      <td>1.568044</td>\n      <td>-0.000756</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.066441e+06</td>\n      <td>674.208648</td>\n      <td>3.816975</td>\n      <td>1.953708</td>\n      <td>0.146233</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.865453e+06</td>\n      <td>1431.583123</td>\n      <td>6.416486</td>\n      <td>2.532814</td>\n      <td>0.358035</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.094965e+07</td>\n      <td>2199.494702</td>\n      <td>26.247583</td>\n      <td>5.123240</td>\n      <td>0.657434</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"performace_on_train = {}\ntrain_evaluate_and_save(\"lr1\", sample_files, data=\"train\", on=\"train\", model=lr, no_print=True, large=False)\npd.DataFrame(performace_on_train).T.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:08:25.830150Z","iopub.execute_input":"2022-06-26T11:08:25.830890Z","iopub.status.idle":"2022-06-26T11:08:27.798720Z","shell.execute_reply.started":"2022-06-26T11:08:25.830851Z","shell.execute_reply":"2022-06-26T11:08:27.797560Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stderr","text":"Training and Evaluating: 100%|██████████| 15/15 [00:01<00:00,  7.95it/s]\n","output_type":"stream"},{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"                mse          mae       msle       rmse         r2\ncount  1.500000e+01    15.000000  15.000000  15.000000  15.000000\nmean   1.997686e+06   676.238625  10.760396   3.008552   0.200098\nstd    3.555184e+06   861.147665   7.576041   1.353176   0.069098\nmin    1.000836e+01     1.618784   0.611311   0.781864   0.065390\n25%    6.791316e+04   162.079612   4.561788   2.124231   0.165562\n50%    3.110485e+05   390.411753  10.404358   3.225579   0.221262\n75%    2.429045e+06   727.681336  15.601187   3.946725   0.239282\nmax    1.287720e+07  3034.101198  23.010674   4.796944   0.303953","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mse</th>\n      <th>mae</th>\n      <th>msle</th>\n      <th>rmse</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.500000e+01</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.997686e+06</td>\n      <td>676.238625</td>\n      <td>10.760396</td>\n      <td>3.008552</td>\n      <td>0.200098</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.555184e+06</td>\n      <td>861.147665</td>\n      <td>7.576041</td>\n      <td>1.353176</td>\n      <td>0.069098</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000836e+01</td>\n      <td>1.618784</td>\n      <td>0.611311</td>\n      <td>0.781864</td>\n      <td>0.065390</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>6.791316e+04</td>\n      <td>162.079612</td>\n      <td>4.561788</td>\n      <td>2.124231</td>\n      <td>0.165562</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.110485e+05</td>\n      <td>390.411753</td>\n      <td>10.404358</td>\n      <td>3.225579</td>\n      <td>0.221262</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.429045e+06</td>\n      <td>727.681336</td>\n      <td>15.601187</td>\n      <td>3.946725</td>\n      <td>0.239282</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.287720e+07</td>\n      <td>3034.101198</td>\n      <td>23.010674</td>\n      <td>4.796944</td>\n      <td>0.303953</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Random Forest","metadata":{}},{"cell_type":"code","source":"rf = RandomForestRegressor(n_estimators=1000, max_depth=10, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:08:49.452014Z","iopub.execute_input":"2022-06-26T11:08:49.452481Z","iopub.status.idle":"2022-06-26T11:08:49.460410Z","shell.execute_reply.started":"2022-06-26T11:08:49.452447Z","shell.execute_reply":"2022-06-26T11:08:49.458360Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"performace_on_test = {}\ntrain_evaluate_and_save(\"rf\", sample_files, data=\"test\", on=\"test\", model=rf, no_print=True, large=False)\npd.DataFrame(performace_on_test).T.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:09:07.533427Z","iopub.execute_input":"2022-06-26T11:09:07.534179Z","iopub.status.idle":"2022-06-26T11:14:48.120531Z","shell.execute_reply.started":"2022-06-26T11:09:07.534136Z","shell.execute_reply":"2022-06-26T11:14:48.119131Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stderr","text":"Training and Evaluating: 100%|██████████| 15/15 [05:40<00:00, 22.70s/it]\n","output_type":"stream"},{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"                mse          mae       msle       rmse         r2\ncount  1.500000e+01    15.000000  15.000000  15.000000  15.000000\nmean   2.311479e+06   569.501702   4.484829   1.887922   0.193206\nstd    5.089915e+06   547.711794   5.189652   0.993144   0.473411\nmin    3.713763e+01     3.537580   0.713562   0.844726  -0.852574\n25%    9.361509e+04   182.859087   1.735264   1.317028  -0.014333\n50%    5.403775e+05   526.276826   2.678668   1.636664   0.110640\n75%    2.285987e+06   791.333685   4.120348   2.028622   0.581855\nmax    2.008099e+07  2063.816129  16.895045   4.110358   0.852973","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mse</th>\n      <th>mae</th>\n      <th>msle</th>\n      <th>rmse</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.500000e+01</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.311479e+06</td>\n      <td>569.501702</td>\n      <td>4.484829</td>\n      <td>1.887922</td>\n      <td>0.193206</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.089915e+06</td>\n      <td>547.711794</td>\n      <td>5.189652</td>\n      <td>0.993144</td>\n      <td>0.473411</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>3.713763e+01</td>\n      <td>3.537580</td>\n      <td>0.713562</td>\n      <td>0.844726</td>\n      <td>-0.852574</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>9.361509e+04</td>\n      <td>182.859087</td>\n      <td>1.735264</td>\n      <td>1.317028</td>\n      <td>-0.014333</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.403775e+05</td>\n      <td>526.276826</td>\n      <td>2.678668</td>\n      <td>1.636664</td>\n      <td>0.110640</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.285987e+06</td>\n      <td>791.333685</td>\n      <td>4.120348</td>\n      <td>2.028622</td>\n      <td>0.581855</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.008099e+07</td>\n      <td>2063.816129</td>\n      <td>16.895045</td>\n      <td>4.110358</td>\n      <td>0.852973</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"performace_on_train = {}\ntrain_evaluate_and_save(\"rf\", sample_files, data=\"train\", on=\"train\", model=rf, no_print=True, large=False)\npd.DataFrame(performace_on_train).T.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:14:48.122503Z","iopub.execute_input":"2022-06-26T11:14:48.122843Z","iopub.status.idle":"2022-06-26T11:20:37.412107Z","shell.execute_reply.started":"2022-06-26T11:14:48.122814Z","shell.execute_reply":"2022-06-26T11:20:37.410887Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stderr","text":"Training and Evaluating: 100%|██████████| 15/15 [05:49<00:00, 23.28s/it]\n","output_type":"stream"},{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"                mse          mae       msle       rmse         r2\ncount  1.500000e+01    15.000000  15.000000  15.000000  15.000000\nmean   1.061514e+06   434.532305   7.485994   2.530623   0.454605\nstd    1.697516e+06   486.283586   4.815403   1.076673   0.153500\nmin    9.090898e+00     1.397402   0.511645   0.715294   0.183116\n25%    4.859324e+04   125.153569   3.514938   1.851915   0.389246\n50%    1.927603e+05   272.945944   8.709275   2.951148   0.445163\n75%    1.778446e+06   537.354415  11.459412   3.384227   0.575474\nmax    5.972714e+06  1696.774924  13.357831   3.654837   0.673452","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mse</th>\n      <th>mae</th>\n      <th>msle</th>\n      <th>rmse</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.500000e+01</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.061514e+06</td>\n      <td>434.532305</td>\n      <td>7.485994</td>\n      <td>2.530623</td>\n      <td>0.454605</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.697516e+06</td>\n      <td>486.283586</td>\n      <td>4.815403</td>\n      <td>1.076673</td>\n      <td>0.153500</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>9.090898e+00</td>\n      <td>1.397402</td>\n      <td>0.511645</td>\n      <td>0.715294</td>\n      <td>0.183116</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>4.859324e+04</td>\n      <td>125.153569</td>\n      <td>3.514938</td>\n      <td>1.851915</td>\n      <td>0.389246</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.927603e+05</td>\n      <td>272.945944</td>\n      <td>8.709275</td>\n      <td>2.951148</td>\n      <td>0.445163</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.778446e+06</td>\n      <td>537.354415</td>\n      <td>11.459412</td>\n      <td>3.384227</td>\n      <td>0.575474</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>5.972714e+06</td>\n      <td>1696.774924</td>\n      <td>13.357831</td>\n      <td>3.654837</td>\n      <td>0.673452</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### XGBoost","metadata":{}},{"cell_type":"code","source":"xgbr = XGBRegressor(n_estimators=1000, max_depth=10)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:23:40.639910Z","iopub.execute_input":"2022-06-26T11:23:40.640285Z","iopub.status.idle":"2022-06-26T11:23:40.646609Z","shell.execute_reply.started":"2022-06-26T11:23:40.640256Z","shell.execute_reply":"2022-06-26T11:23:40.645200Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"performace_on_test = {}\ntrain_evaluate_and_save(\"xgbr\", sample_files, data=\"test\", on=\"test\", model=xgbr, no_print=True, large=False)\npd.DataFrame(performace_on_test).T.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:24:14.522302Z","iopub.execute_input":"2022-06-26T11:24:14.522734Z","iopub.status.idle":"2022-06-26T11:27:36.319280Z","shell.execute_reply.started":"2022-06-26T11:24:14.522701Z","shell.execute_reply":"2022-06-26T11:27:36.318076Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stderr","text":"Training and Evaluating: 100%|██████████| 15/15 [03:21<00:00, 13.45s/it]\n","output_type":"stream"},{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"                mse          mae       msle       rmse         r2\ncount  1.500000e+01    15.000000  15.000000  15.000000  15.000000\nmean   6.067002e+06   700.551601   4.472057   1.930714  -0.230158\nstd    1.845003e+07   843.923299   4.605227   0.893070   1.563951\nmin    4.073130e+01     3.596807   1.158664   1.076413  -5.686210\n25%    1.050216e+05   191.948457   1.684837   1.297502  -0.195258\n50%    5.810588e+05   530.238249   3.154223   1.776013   0.084282\n75%    2.970035e+06   871.913015   4.183369   2.044772   0.507328\nmax    7.247730e+07  3369.247564  15.708357   3.963377   0.831105","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mse</th>\n      <th>mae</th>\n      <th>msle</th>\n      <th>rmse</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.500000e+01</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>6.067002e+06</td>\n      <td>700.551601</td>\n      <td>4.472057</td>\n      <td>1.930714</td>\n      <td>-0.230158</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.845003e+07</td>\n      <td>843.923299</td>\n      <td>4.605227</td>\n      <td>0.893070</td>\n      <td>1.563951</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.073130e+01</td>\n      <td>3.596807</td>\n      <td>1.158664</td>\n      <td>1.076413</td>\n      <td>-5.686210</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.050216e+05</td>\n      <td>191.948457</td>\n      <td>1.684837</td>\n      <td>1.297502</td>\n      <td>-0.195258</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.810588e+05</td>\n      <td>530.238249</td>\n      <td>3.154223</td>\n      <td>1.776013</td>\n      <td>0.084282</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.970035e+06</td>\n      <td>871.913015</td>\n      <td>4.183369</td>\n      <td>2.044772</td>\n      <td>0.507328</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.247730e+07</td>\n      <td>3369.247564</td>\n      <td>15.708357</td>\n      <td>3.963377</td>\n      <td>0.831105</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"performace_on_train = {}\ntrain_evaluate_and_save(\"xgbr\", sample_files, data=\"train\", on=\"train\", model=xgbr, no_print=True, large=False)\npd.DataFrame(performace_on_train).T.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:27:36.321485Z","iopub.execute_input":"2022-06-26T11:27:36.321849Z","iopub.status.idle":"2022-06-26T11:31:03.914512Z","shell.execute_reply.started":"2022-06-26T11:27:36.321817Z","shell.execute_reply":"2022-06-26T11:31:03.913600Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stderr","text":"Training and Evaluating: 100%|██████████| 15/15 [03:27<00:00, 13.84s/it]\n","output_type":"stream"},{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"                mse          mae       msle       rmse         r2\ncount  1.500000e+01    15.000000  15.000000  15.000000  15.000000\nmean   9.319450e+05   364.197096   6.701980   2.400056   0.500509\nstd    1.509731e+06   393.910759   4.233168   1.004479   0.168428\nmin    9.053522e+00     1.393042   0.510545   0.714525   0.186475\n25%    4.394832e+04   111.176642   3.231910   1.764101   0.424801\n50%    1.388530e+05   228.351451   8.321409   2.884685   0.483685\n75%    1.709061e+06   503.121995   9.732247   3.118878   0.641070\nmax    5.425655e+06  1410.233220  12.693816   3.562838   0.755850","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mse</th>\n      <th>mae</th>\n      <th>msle</th>\n      <th>rmse</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.500000e+01</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>9.319450e+05</td>\n      <td>364.197096</td>\n      <td>6.701980</td>\n      <td>2.400056</td>\n      <td>0.500509</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.509731e+06</td>\n      <td>393.910759</td>\n      <td>4.233168</td>\n      <td>1.004479</td>\n      <td>0.168428</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>9.053522e+00</td>\n      <td>1.393042</td>\n      <td>0.510545</td>\n      <td>0.714525</td>\n      <td>0.186475</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>4.394832e+04</td>\n      <td>111.176642</td>\n      <td>3.231910</td>\n      <td>1.764101</td>\n      <td>0.424801</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.388530e+05</td>\n      <td>228.351451</td>\n      <td>8.321409</td>\n      <td>2.884685</td>\n      <td>0.483685</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.709061e+06</td>\n      <td>503.121995</td>\n      <td>9.732247</td>\n      <td>3.118878</td>\n      <td>0.641070</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>5.425655e+06</td>\n      <td>1410.233220</td>\n      <td>12.693816</td>\n      <td>3.562838</td>\n      <td>0.755850</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"It seems the models are not performin good enough on the *small* dataset. Next, we'll see if using the *large* dataset changes this.","metadata":{}},{"cell_type":"markdown","source":"## The *Large* Dataset","metadata":{}},{"cell_type":"code","source":"random.seed(42)\nTRAIN_DIR = \"data/large/train_large\"\nTEST_DIR = \"data/large/test_large\"\n\nall_files = os.listdir(TRAIN_DIR)\nsample_files = random.sample(all_files, 15)\nsample_files","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:31:03.916234Z","iopub.execute_input":"2022-06-26T11:31:03.917063Z","iopub.status.idle":"2022-06-26T11:31:03.924569Z","shell.execute_reply.started":"2022-06-26T11:31:03.917029Z","shell.execute_reply":"2022-06-26T11:31:03.923473Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"['A_BOOKS.csv',\n 'B_LADIESWEAR.csv',\n 'H_EGGS.csv',\n 'L_POULTRY.csv',\n 'G_HOME CARE.csv',\n 'F_LADIESWEAR.csv',\n 'A_HOME AND KITCHEN II.csv',\n 'E_BEAUTY.csv',\n 'O_LIQUOR,WINE,BEER.csv',\n 'Q_HOME APPLIANCES.csv',\n 'P_CLEANING.csv',\n 'M_PET SUPPLIES.csv',\n 'G_BABY CARE.csv',\n 'A_PLAYERS AND ELECTRONICS.csv',\n 'I_HOME AND KITCHEN I.csv']"},"metadata":{}}]},{"cell_type":"markdown","source":"### Linear Model","metadata":{}},{"cell_type":"code","source":"lr = LinearRegression()\nperformace_on_test = {}\ntrain_evaluate_and_save(\"lr\", sample_files, data=\"test\", on=\"test\", model=lr, no_print=True)\npd.DataFrame(performace_on_test).T.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:31:03.953008Z","iopub.execute_input":"2022-06-26T11:31:03.953365Z","iopub.status.idle":"2022-06-26T11:31:04.918116Z","shell.execute_reply.started":"2022-06-26T11:31:03.953334Z","shell.execute_reply":"2022-06-26T11:31:04.917054Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stderr","text":"Training and Evaluating: 100%|██████████| 15/15 [00:00<00:00, 16.16it/s]\n","output_type":"stream"},{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"                 mse         mae       msle       rmse         r2\ncount      15.000000   15.000000  15.000000  15.000000  15.000000\nmean    31156.016606   71.365476   1.596567   0.918198  -0.161984\nstd     77980.417811  132.554349   3.056029   0.898498   0.964735\nmin         0.000000    0.000000   0.000000   0.000000  -2.830644\n25%        18.382486    2.959447   0.254179   0.502207  -0.106281\n50%       111.614703    7.763896   0.528386   0.726902   0.016556\n75%      3524.990518   47.127334   0.866028   0.929508   0.127165\nmax    288172.938601  465.330789  10.117823   3.180853   1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mse</th>\n      <th>mae</th>\n      <th>msle</th>\n      <th>rmse</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>31156.016606</td>\n      <td>71.365476</td>\n      <td>1.596567</td>\n      <td>0.918198</td>\n      <td>-0.161984</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>77980.417811</td>\n      <td>132.554349</td>\n      <td>3.056029</td>\n      <td>0.898498</td>\n      <td>0.964735</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-2.830644</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>18.382486</td>\n      <td>2.959447</td>\n      <td>0.254179</td>\n      <td>0.502207</td>\n      <td>-0.106281</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>111.614703</td>\n      <td>7.763896</td>\n      <td>0.528386</td>\n      <td>0.726902</td>\n      <td>0.016556</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3524.990518</td>\n      <td>47.127334</td>\n      <td>0.866028</td>\n      <td>0.929508</td>\n      <td>0.127165</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>288172.938601</td>\n      <td>465.330789</td>\n      <td>10.117823</td>\n      <td>3.180853</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"performace_on_train = {}\ntrain_evaluate_and_save(\"lr\", sample_files, data=\"train\", on=\"train\", model=lr, no_print=True)\npd.DataFrame(performace_on_train).T.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:31:04.919785Z","iopub.execute_input":"2022-06-26T11:31:04.920124Z","iopub.status.idle":"2022-06-26T11:31:05.976901Z","shell.execute_reply.started":"2022-06-26T11:31:04.920093Z","shell.execute_reply":"2022-06-26T11:31:05.975616Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stderr","text":"Training and Evaluating: 100%|██████████| 15/15 [00:01<00:00, 14.91it/s]\n","output_type":"stream"},{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"                mse         mae       msle       rmse         r2\ncount     15.000000   15.000000  15.000000  15.000000  15.000000\nmean   11561.938703   38.924385   2.376570   1.202824   0.354442\nstd    23276.221883   62.417911   3.691862   0.998097   0.286141\nmin        0.000000    0.000000   0.000000   0.000000   0.004840\n25%        6.696696    1.870894   0.430865   0.654525   0.208603\n50%       68.910501    5.062088   0.998394   0.999197   0.280002\n75%     2269.308054   35.257498   2.485220   1.573385   0.370634\nmax    66418.809861  173.180729  14.050695   3.748426   1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mse</th>\n      <th>mae</th>\n      <th>msle</th>\n      <th>rmse</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>11561.938703</td>\n      <td>38.924385</td>\n      <td>2.376570</td>\n      <td>1.202824</td>\n      <td>0.354442</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>23276.221883</td>\n      <td>62.417911</td>\n      <td>3.691862</td>\n      <td>0.998097</td>\n      <td>0.286141</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.004840</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>6.696696</td>\n      <td>1.870894</td>\n      <td>0.430865</td>\n      <td>0.654525</td>\n      <td>0.208603</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>68.910501</td>\n      <td>5.062088</td>\n      <td>0.998394</td>\n      <td>0.999197</td>\n      <td>0.280002</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2269.308054</td>\n      <td>35.257498</td>\n      <td>2.485220</td>\n      <td>1.573385</td>\n      <td>0.370634</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>66418.809861</td>\n      <td>173.180729</td>\n      <td>14.050695</td>\n      <td>3.748426</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Okay, we are getting better result. Let's try some other models.","metadata":{}},{"cell_type":"markdown","source":"### The Random Forest","metadata":{}},{"cell_type":"code","source":"rf = RandomForestRegressor(n_estimators=1000, max_depth=10, random_state=42)\nperformace_on_test = {}\ntrain_evaluate_and_save(\"rf\", sample_files, data=\"test\", on=\"test\", model=rf, no_print=True)\npd.DataFrame(performace_on_test).T.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:54:46.817140Z","iopub.execute_input":"2022-06-26T11:54:46.817598Z","iopub.status.idle":"2022-06-26T11:56:01.982052Z","shell.execute_reply.started":"2022-06-26T11:54:46.817555Z","shell.execute_reply":"2022-06-26T11:56:01.980912Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stderr","text":"Training and Evaluating: 100%|██████████| 15/15 [01:15<00:00,  5.01s/it]\n","output_type":"stream"},{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"                mse         mae       msle       rmse         r2\ncount     15.000000   15.000000  15.000000  15.000000  15.000000\nmean    9968.896730   43.523844   1.111628   0.841592  -0.016960\nstd    20108.455295   65.830668   1.729493   0.657390   0.766834\nmin        0.000000    0.000000   0.000000   0.000000  -2.046899\n25%       20.595052    3.012009   0.332618   0.576454  -0.119413\n50%      115.195531    7.536792   0.573305   0.757169  -0.034446\n75%     3411.787172   44.662401   0.818019   0.904442   0.472006\nmax    64716.101791  186.827537   5.720232   2.391701   1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mse</th>\n      <th>mae</th>\n      <th>msle</th>\n      <th>rmse</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>9968.896730</td>\n      <td>43.523844</td>\n      <td>1.111628</td>\n      <td>0.841592</td>\n      <td>-0.016960</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>20108.455295</td>\n      <td>65.830668</td>\n      <td>1.729493</td>\n      <td>0.657390</td>\n      <td>0.766834</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-2.046899</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>20.595052</td>\n      <td>3.012009</td>\n      <td>0.332618</td>\n      <td>0.576454</td>\n      <td>-0.119413</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>115.195531</td>\n      <td>7.536792</td>\n      <td>0.573305</td>\n      <td>0.757169</td>\n      <td>-0.034446</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3411.787172</td>\n      <td>44.662401</td>\n      <td>0.818019</td>\n      <td>0.904442</td>\n      <td>0.472006</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>64716.101791</td>\n      <td>186.827537</td>\n      <td>5.720232</td>\n      <td>2.391701</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"rf = RandomForestRegressor(n_estimators=1000, max_depth=10, random_state=42)\nperformace_on_train = {}\ntrain_evaluate_and_save(\"rf\", sample_files, data=\"train\", on=\"train\", model=rf, no_print=True)\npd.DataFrame(performace_on_train).T.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:56:55.893059Z","iopub.execute_input":"2022-06-26T11:56:55.893503Z","iopub.status.idle":"2022-06-26T11:58:13.214831Z","shell.execute_reply.started":"2022-06-26T11:56:55.893472Z","shell.execute_reply":"2022-06-26T11:58:13.213634Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stderr","text":"Training and Evaluating: 100%|██████████| 15/15 [01:17<00:00,  5.15s/it]\n","output_type":"stream"},{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"                mse         mae       msle       rmse         r2\ncount     15.000000   15.000000  15.000000  15.000000  15.000000\nmean    4568.740911   24.709947   1.165115   0.789872   0.639216\nstd     9323.191939   39.109337   1.912266   0.761496   0.201735\nmin        0.000000    0.000000   0.000000   0.000000   0.393078\n25%        4.862756    1.474496   0.122756   0.349560   0.472793\n50%       52.403624    3.870721   0.368265   0.606849   0.611049\n75%     1572.876187   29.079232   0.465209   0.681927   0.765063\nmax    26840.686955  125.325199   5.431083   2.330468   1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mse</th>\n      <th>mae</th>\n      <th>msle</th>\n      <th>rmse</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4568.740911</td>\n      <td>24.709947</td>\n      <td>1.165115</td>\n      <td>0.789872</td>\n      <td>0.639216</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9323.191939</td>\n      <td>39.109337</td>\n      <td>1.912266</td>\n      <td>0.761496</td>\n      <td>0.201735</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.393078</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>4.862756</td>\n      <td>1.474496</td>\n      <td>0.122756</td>\n      <td>0.349560</td>\n      <td>0.472793</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>52.403624</td>\n      <td>3.870721</td>\n      <td>0.368265</td>\n      <td>0.606849</td>\n      <td>0.611049</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1572.876187</td>\n      <td>29.079232</td>\n      <td>0.465209</td>\n      <td>0.681927</td>\n      <td>0.765063</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>26840.686955</td>\n      <td>125.325199</td>\n      <td>5.431083</td>\n      <td>2.330468</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### The XGBoost","metadata":{}},{"cell_type":"code","source":"xgbr = XGBRegressor(n_estimators=1000, max_depth=5)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T12:30:57.489284Z","iopub.execute_input":"2022-06-26T12:30:57.489912Z","iopub.status.idle":"2022-06-26T12:30:57.497082Z","shell.execute_reply.started":"2022-06-26T12:30:57.489863Z","shell.execute_reply":"2022-06-26T12:30:57.496064Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"performace_on_test = {}\ntrain_evaluate_and_save(\"xgbr\", sample_files, data=\"test\", on=\"test\", model=xgbr, no_print=True)\npd.DataFrame(performace_on_test).T.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T12:30:57.934463Z","iopub.execute_input":"2022-06-26T12:30:57.935827Z","iopub.status.idle":"2022-06-26T12:32:13.498217Z","shell.execute_reply.started":"2022-06-26T12:30:57.935775Z","shell.execute_reply":"2022-06-26T12:32:13.496388Z"},"trusted":true},"execution_count":107,"outputs":[{"name":"stderr","text":"Training and Evaluating: 100%|██████████| 15/15 [01:15<00:00,  5.04s/it]\n","output_type":"stream"},{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"                mse           mae          msle          rmse         r2\ncount  1.500000e+01  1.500000e+01  1.500000e+01  1.500000e+01  15.000000\nmean   1.305441e+04  4.534583e+01  1.019564e+00  8.349887e-01  -0.352443\nstd    2.677326e+04  6.635634e+01  1.374298e+00  5.876934e-01   1.090654\nmin    1.963637e-90  1.401298e-45  1.963637e-90  1.401298e-45  -4.080264\n25%    2.031117e+01  3.061301e+00  3.428402e-01  5.855020e-01  -0.297274\n50%    1.385080e+02  8.151645e+00  6.475291e-01  8.046919e-01  -0.125066\n75%    4.905504e+03  5.242832e+01  8.457056e-01  9.195562e-01   0.003602\nmax    9.032008e+04  1.799161e+02  4.412108e+00  2.100502e+00   0.575567","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mse</th>\n      <th>mae</th>\n      <th>msle</th>\n      <th>rmse</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.500000e+01</td>\n      <td>1.500000e+01</td>\n      <td>1.500000e+01</td>\n      <td>1.500000e+01</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.305441e+04</td>\n      <td>4.534583e+01</td>\n      <td>1.019564e+00</td>\n      <td>8.349887e-01</td>\n      <td>-0.352443</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.677326e+04</td>\n      <td>6.635634e+01</td>\n      <td>1.374298e+00</td>\n      <td>5.876934e-01</td>\n      <td>1.090654</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.963637e-90</td>\n      <td>1.401298e-45</td>\n      <td>1.963637e-90</td>\n      <td>1.401298e-45</td>\n      <td>-4.080264</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.031117e+01</td>\n      <td>3.061301e+00</td>\n      <td>3.428402e-01</td>\n      <td>5.855020e-01</td>\n      <td>-0.297274</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.385080e+02</td>\n      <td>8.151645e+00</td>\n      <td>6.475291e-01</td>\n      <td>8.046919e-01</td>\n      <td>-0.125066</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.905504e+03</td>\n      <td>5.242832e+01</td>\n      <td>8.457056e-01</td>\n      <td>9.195562e-01</td>\n      <td>0.003602</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.032008e+04</td>\n      <td>1.799161e+02</td>\n      <td>4.412108e+00</td>\n      <td>2.100502e+00</td>\n      <td>0.575567</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"performace_on_train = {}\ntrain_evaluate_and_save(\"xgbr\", sample_files, data=\"train\", on=\"train\", model=xgbr, no_print=True)\npd.DataFrame(performace_on_train).T.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T12:32:13.500334Z","iopub.execute_input":"2022-06-26T12:32:13.500637Z","iopub.status.idle":"2022-06-26T12:33:28.604155Z","shell.execute_reply.started":"2022-06-26T12:32:13.500608Z","shell.execute_reply":"2022-06-26T12:33:28.602991Z"},"trusted":true},"execution_count":108,"outputs":[{"name":"stderr","text":"Training and Evaluating: 100%|██████████| 15/15 [01:15<00:00,  5.00s/it]\n","output_type":"stream"},{"execution_count":108,"output_type":"execute_result","data":{"text/plain":"                mse           mae          msle          rmse         r2\ncount  1.500000e+01  1.500000e+01  1.500000e+01  1.500000e+01  15.000000\nmean   1.748848e+03  1.016915e+01  7.366152e-01  5.777844e-01   0.601976\nstd    5.897340e+03  2.012600e+01  1.462354e+00  6.569249e-01   0.316004\nmin    1.963637e-90  1.401298e-45  1.963637e-90  1.401298e-45   0.000000\n25%    2.732988e+00  9.550996e-01  1.551947e-02  1.195218e-01   0.467409\n50%    9.015534e+00  1.769470e+00  2.523036e-01  5.022983e-01   0.608614\n75%    2.060753e+02  7.778900e+00  3.990347e-01  6.316047e-01   0.826786\nmax    2.295380e+04  7.475575e+01  4.704983e+00  2.169097e+00   0.999977","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mse</th>\n      <th>mae</th>\n      <th>msle</th>\n      <th>rmse</th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.500000e+01</td>\n      <td>1.500000e+01</td>\n      <td>1.500000e+01</td>\n      <td>1.500000e+01</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.748848e+03</td>\n      <td>1.016915e+01</td>\n      <td>7.366152e-01</td>\n      <td>5.777844e-01</td>\n      <td>0.601976</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.897340e+03</td>\n      <td>2.012600e+01</td>\n      <td>1.462354e+00</td>\n      <td>6.569249e-01</td>\n      <td>0.316004</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.963637e-90</td>\n      <td>1.401298e-45</td>\n      <td>1.963637e-90</td>\n      <td>1.401298e-45</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.732988e+00</td>\n      <td>9.550996e-01</td>\n      <td>1.551947e-02</td>\n      <td>1.195218e-01</td>\n      <td>0.467409</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>9.015534e+00</td>\n      <td>1.769470e+00</td>\n      <td>2.523036e-01</td>\n      <td>5.022983e-01</td>\n      <td>0.608614</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.060753e+02</td>\n      <td>7.778900e+00</td>\n      <td>3.990347e-01</td>\n      <td>6.316047e-01</td>\n      <td>0.826786</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.295380e+04</td>\n      <td>7.475575e+01</td>\n      <td>4.704983e+00</td>\n      <td>2.169097e+00</td>\n      <td>0.999977</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Okay, let's make predictions on the test dataset.","metadata":{}},{"cell_type":"code","source":"df = train_and_predict(xgbr, all_files[0])\nfor file in tqdm.tqdm(all_files[1:], desc=\"Predicting...\"):\n    df_temp = train_and_predict(rf, file)\n    df = pd.concat([df, df_temp])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T12:39:51.629611Z","iopub.execute_input":"2022-06-26T12:39:51.630062Z","iopub.status.idle":"2022-06-26T13:35:21.732570Z","shell.execute_reply.started":"2022-06-26T12:39:51.630031Z","shell.execute_reply":"2022-06-26T13:35:21.731583Z"},"trusted":true},"execution_count":109,"outputs":[{"name":"stderr","text":"Predicting...: 100%|██████████| 560/560 [55:24<00:00,  5.94s/it]  \n","output_type":"stream"}]},{"cell_type":"code","source":"df\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T13:49:49.038579Z","iopub.execute_input":"2022-06-26T13:49:49.040123Z","iopub.status.idle":"2022-06-26T13:49:49.054981Z","shell.execute_reply.started":"2022-06-26T13:49:49.040072Z","shell.execute_reply":"2022-06-26T13:49:49.054105Z"},"trusted":true},"execution_count":110,"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"         id       sales\n0   3001150   82.642387\n1   3001678   82.642387\n2   3001744   82.642387\n3   3001777   82.642387\n4   3001843   82.642387\n..      ...         ...\n43  3027537  331.066005\n44  3027570  331.077897\n45  3028362  393.053604\n46  3029319  316.698405\n47  3029352  385.674312\n\n[28512 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3001150</td>\n      <td>82.642387</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3001678</td>\n      <td>82.642387</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3001744</td>\n      <td>82.642387</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3001777</td>\n      <td>82.642387</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3001843</td>\n      <td>82.642387</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>3027537</td>\n      <td>331.066005</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>3027570</td>\n      <td>331.077897</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>3028362</td>\n      <td>393.053604</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>3029319</td>\n      <td>316.698405</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>3029352</td>\n      <td>385.674312</td>\n    </tr>\n  </tbody>\n</table>\n<p>28512 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_ordered = df.sort_values(by=\"id\")\ndf_ordered","metadata":{"execution":{"iopub.status.busy":"2022-06-26T13:50:31.190918Z","iopub.execute_input":"2022-06-26T13:50:31.191351Z","iopub.status.idle":"2022-06-26T13:50:31.209181Z","shell.execute_reply.started":"2022-06-26T13:50:31.191321Z","shell.execute_reply":"2022-06-26T13:50:31.208252Z"},"trusted":true},"execution_count":112,"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"         id        sales\n0   3000888     6.061122\n0   3000889     0.088900\n0   3000890     5.591964\n0   3000891  2525.394851\n0   3000892     0.000000\n..      ...          ...\n95  3029395   260.838431\n95  3029396    61.289081\n95  3029397   963.587138\n95  3029398    28.548445\n95  3029399     7.976593\n\n[28512 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3000888</td>\n      <td>6.061122</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>3000889</td>\n      <td>0.088900</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>3000890</td>\n      <td>5.591964</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>3000891</td>\n      <td>2525.394851</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>3000892</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>3029395</td>\n      <td>260.838431</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>3029396</td>\n      <td>61.289081</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>3029397</td>\n      <td>963.587138</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>3029398</td>\n      <td>28.548445</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>3029399</td>\n      <td>7.976593</td>\n    </tr>\n  </tbody>\n</table>\n<p>28512 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_ordered[\"sales\"] = df_ordered[\"sales\"].apply(lambda x: np.abs(x))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T13:50:47.854185Z","iopub.execute_input":"2022-06-26T13:50:47.854783Z","iopub.status.idle":"2022-06-26T13:50:47.893891Z","shell.execute_reply.started":"2022-06-26T13:50:47.854732Z","shell.execute_reply":"2022-06-26T13:50:47.892474Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"df_ordered.describe()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T13:50:48.298181Z","iopub.execute_input":"2022-06-26T13:50:48.299249Z","iopub.status.idle":"2022-06-26T13:50:48.320187Z","shell.execute_reply.started":"2022-06-26T13:50:48.299206Z","shell.execute_reply":"2022-06-26T13:50:48.319274Z"},"trusted":true},"execution_count":114,"outputs":[{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"                 id         sales\ncount  2.851200e+04  28512.000000\nmean   3.015144e+06    444.403082\nstd    8.230850e+03   1161.606446\nmin    3.000888e+06      0.000000\n25%    3.008016e+06      4.007548\n50%    3.015144e+06     26.670612\n75%    3.022271e+06    273.915931\nmax    3.029399e+06  13034.466247","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2.851200e+04</td>\n      <td>28512.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.015144e+06</td>\n      <td>444.403082</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.230850e+03</td>\n      <td>1161.606446</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>3.000888e+06</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3.008016e+06</td>\n      <td>4.007548</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.015144e+06</td>\n      <td>26.670612</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.022271e+06</td>\n      <td>273.915931</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.029399e+06</td>\n      <td>13034.466247</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_ordered.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T13:51:35.455311Z","iopub.execute_input":"2022-06-26T13:51:35.455668Z","iopub.status.idle":"2022-06-26T13:51:35.530254Z","shell.execute_reply.started":"2022-06-26T13:51:35.455641Z","shell.execute_reply":"2022-06-26T13:51:35.529009Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"!kaggle competitions submit -c store-sales-time-series-forecasting -f data/submissions/submission_4.csv -m \"Submission 4\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great!","metadata":{}}]}